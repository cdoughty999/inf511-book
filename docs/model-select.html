<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>INF511: Modern Regression I - 7&nbsp; Model selection</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./anova.html" rel="next">
<link href="./max-lik.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Model selection</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">INF511: Modern Regression I</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/joseph-mihaljevic/inf511-book" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Software</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Rintro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hypothesis.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./max-lik.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./model-select.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Model selection</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">ANOVA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayesian.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Bayesian inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">Appendices</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./syllabus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Syllabus</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#lecture-material" id="toc-lecture-material" class="nav-link active" data-scroll-target="#lecture-material"><span class="toc-section-number">7.1</span>  Lecture material</a></li>
  <li><a href="#sec-data" id="toc-sec-data" class="nav-link" data-scroll-target="#sec-data"><span class="toc-section-number">7.2</span>  Generate the data</a></li>
  <li><a href="#parsimony-via-model-simplification" id="toc-parsimony-via-model-simplification" class="nav-link" data-scroll-target="#parsimony-via-model-simplification"><span class="toc-section-number">7.3</span>  Parsimony via model simplification</a></li>
  <li><a href="#model-averaging" id="toc-model-averaging" class="nav-link" data-scroll-target="#model-averaging"><span class="toc-section-number">7.4</span>  Model averaging</a>
  <ul class="collapse">
  <li><a href="#required-calculations" id="toc-required-calculations" class="nav-link" data-scroll-target="#required-calculations"><span class="toc-section-number">7.4.1</span>  Required calculations</a></li>
  <li><a href="#manual-calculation" id="toc-manual-calculation" class="nav-link" data-scroll-target="#manual-calculation"><span class="toc-section-number">7.4.2</span>  Manual calculation</a></li>
  <li><a href="#back-to-more-complex-model" id="toc-back-to-more-complex-model" class="nav-link" data-scroll-target="#back-to-more-complex-model"><span class="toc-section-number">7.4.3</span>  Back to more complex model</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/joseph-mihaljevic/inf511-book/blob/main/model-select.qmd" class="toc-action">View source</a></p><p><a href="https://github.com/joseph-mihaljevic/inf511-book/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-modelselect" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Model selection</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="lecture-material" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="lecture-material"><span class="header-section-number">7.1</span> Lecture material</h2>
<p>Please download and print the lecture materials from <a href="https://bblearn.nau.edu/" target="_blank">Bblearn</a>. After lectures, the recordings will appear in the Bblearn Collaborate Ultra section.</p>
</section>
<section id="sec-data" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="sec-data"><span class="header-section-number">7.2</span> Generate the data</h2>
<p>Here we will demonstrate two approaches to model comparison. But first let’s generate data, in the same way we did for multiple linear regression in (<a href="ols.html"><span>Chapter&nbsp;4</span></a>). Note that in this case, we will specify that two of the input variables have zero slope (i.e., no linear association with the outcome variable).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">40</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>n_covariate <span class="ot">=</span> <span class="dv">4</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> n_covariate <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">=</span> <span class="fu">vector</span>(<span class="st">"numeric"</span>, <span class="at">length =</span> p)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>xmat <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n, <span class="at">ncol =</span> p)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fl">2.25</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Column for intercept</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">1</span>] <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the covariate data randomly:</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">2</span>] <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">8</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">3</span>] <span class="ot">=</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">20</span>)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">4</span>] <span class="ot">=</span> <span class="fu">rchisq</span>(n, <span class="at">df =</span> <span class="dv">50</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">5</span>] <span class="ot">=</span> <span class="fu">rpois</span>(n, <span class="at">lambda =</span> <span class="dv">10</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the betas:</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">1</span>] <span class="ot">=</span> <span class="fl">1.0</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">2</span>] <span class="ot">=</span> <span class="fl">0.0</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">3</span>] <span class="ot">=</span> <span class="sc">-</span><span class="fl">0.2</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">4</span>] <span class="ot">=</span> <span class="fl">0.0</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">5</span>] <span class="ot">=</span> <span class="fl">1.8</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the observed 'y', adding residual error</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> xmat <span class="sc">%*%</span> betas <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>p){</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(y <span class="sc">~</span> xmat[,i],</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="fu">paste</span>(<span class="st">"covariate "</span>, i<span class="dv">-1</span>))</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="model-select_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data.frame</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>my_df <span class="ot">=</span> <span class="fu">data.frame</span>(y, xmat[,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(my_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          y         X1        X2       X3 X4
1 28.492690 -1.7268438 18.788730 38.39431 18
2 14.221411 16.0748747 16.474910 60.76146 10
3  9.064956 -5.0439349  4.223082 33.40577  5
4  9.366421  5.5611421  1.832589 41.76465  5
5 18.874673 18.6915270  9.405498 40.26706 11
6 17.706978  0.1767361  1.001228 46.05881 10</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the model, report the summary</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3 <span class="sc">+</span> X4, <span class="at">data =</span> my_df)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>m1_summary <span class="ot">=</span> <span class="fu">summary</span>(m1)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>m1_summary</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ 1 + X1 + X2 + X3 + X4, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3257 -1.4053 -0.4331  1.3299  4.3178 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  3.41757    1.82632   1.871  0.06968 .  
X1           0.03245    0.03810   0.852  0.40016    
X2          -0.26989    0.07297  -3.698  0.00074 ***
X3          -0.01823    0.03267  -0.558  0.58050    
X4           1.68543    0.11083  15.207  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.94 on 35 degrees of freedom
Multiple R-squared:  0.8901,    Adjusted R-squared:  0.8775 
F-statistic: 70.86 on 4 and 35 DF,  p-value: 2.741e-16</code></pre>
</div>
</div>
</section>
<section id="parsimony-via-model-simplification" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="parsimony-via-model-simplification"><span class="header-section-number">7.3</span> Parsimony via model simplification</h2>
<p>We will successively simplify the model until we find a “minimally acceptable” model that explains the most variability in the outcome variable.</p>
<p>There are several built-in functions in R that can help us make quantitatively justified decisions about which input variables can be dropped from the full model to determine our minimally acceptable model. First, we can use the <span class="math inline">\(F\)</span>-test as described in lecture. This can be implemented by the <code>anova()</code> function.</p>
<p>Based on the <code>summary()</code> output, we see that input variable 3 (<span class="math inline">\(x_3\)</span>) has the least significant effect on <span class="math inline">\(y\)</span>, so we will drop that first and proceed from there.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The full model lives in object m1</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">formula</span>(m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>y ~ 1 + X1 + X2 + X3 + X4</code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new model with the update() function</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This function has a strange notation, but so it goes...</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">=</span> <span class="fu">update</span>(m1, .<span class="sc">~</span>. <span class="sc">-</span>X3)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="fu">formula</span>(m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>y ~ X1 + X2 + X4</code></pre>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ X1 + X2 + X4, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4492 -1.3713 -0.3323  1.2450  4.3718 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.54371    0.92986   2.736 0.009605 ** 
X1           0.02863    0.03712   0.771 0.445496    
X2          -0.26530    0.07181  -3.694 0.000728 ***
X4           1.68217    0.10962  15.346  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.921 on 36 degrees of freedom
Multiple R-squared:  0.8891,    Adjusted R-squared:  0.8799 
F-statistic: 96.22 on 3 and 36 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use anova() to test if the drop of X3 is justified</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m2, m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ X1 + X2 + X4
Model 2: y ~ 1 + X1 + X2 + X3 + X4
  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1     36 132.91                           
2     35 131.73  1    1.1712 0.3112 0.5805</code></pre>
</div>
</div>
<p>Remember that the hypothesis tested is: <span class="math display">\[H_0:\text{simple model}\]</span> <span class="math display">\[H_A:\text{complex model}\]</span> So if the <span class="math inline">\(p \ge 0.05\)</span>, as usual, we cannot reject the null hypothesis. In this case, it means that the simple model is just as good as the more complex model. Therefore, we are justified in dropping <span class="math inline">\(x_3\)</span>. From the data, we could not detect that <span class="math inline">\(x_3\)</span> has a statistically meaningful linear relationship with the outcome data <span class="math inline">\(y\)</span>.</p>
<p>Let’s manually calculate that <span class="math inline">\(F\)</span> test statistic and associated <span class="math inline">\(p\)</span>-value to verify that we understand how the test works.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the residuals (errors)</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>resid_null <span class="ot">=</span> m2<span class="sc">$</span>residuals</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>resid_full <span class="ot">=</span> m1<span class="sc">$</span>residuals</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of Square Errors (SSE)</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>sse_null <span class="ot">=</span> <span class="fu">crossprod</span>(resid_null)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>sse_full <span class="ot">=</span> <span class="fu">crossprod</span>(resid_full)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co"># degrees of freedom</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>df_null <span class="ot">=</span> n<span class="sc">-</span>(p<span class="dv">-1</span>) <span class="co"># we dropped one input variable</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>df_full <span class="ot">=</span> n<span class="sc">-</span>p</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate F_stat</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>f_test <span class="ot">=</span> ((sse_null <span class="sc">-</span> sse_full)<span class="sc">/</span>(df_null <span class="sc">-</span> df_full)) <span class="sc">/</span> (sse_full<span class="sc">/</span>df_full)</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of freedom for the F distribution:</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>df_numerator <span class="ot">=</span> df_null <span class="sc">-</span> df_full</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>df_denominator <span class="ot">=</span> df_full</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>p_m1vm2 <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pf</span>(f_test,</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>                <span class="at">df1 =</span> df_numerator,</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>                <span class="at">df2 =</span> df_denominator)</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to anova()</span></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>f_test; p_m1vm2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]
[1,] 0.3111883</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]
[1,] 0.5805028</code></pre>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>anova_m1vm2 <span class="ot">=</span> <span class="fu">anova</span>(m2,m1)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>anova_m1vm2<span class="sc">$</span><span class="st">`</span><span class="at">F</span><span class="st">`</span>; anova_m1vm2<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]        NA 0.3111883</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1]        NA 0.5805028</code></pre>
</div>
</div>
<p>Let’s continue with the simplification process, using the <code>anova()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># model 2 is the current best.</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ X1 + X2 + X4, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4492 -1.3713 -0.3323  1.2450  4.3718 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.54371    0.92986   2.736 0.009605 ** 
X1           0.02863    0.03712   0.771 0.445496    
X2          -0.26530    0.07181  -3.694 0.000728 ***
X4           1.68217    0.10962  15.346  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.921 on 36 degrees of freedom
Multiple R-squared:  0.8891,    Adjusted R-squared:  0.8799 
F-statistic: 96.22 on 3 and 36 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, drop x1 and check</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">=</span> <span class="fu">update</span>(m2, .<span class="sc">~</span>. <span class="sc">-</span>X1)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Check:</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m3, m2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ X2 + X4
Model 2: y ~ X1 + X2 + X4
  Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
1     37 135.10                           
2     36 132.91  1    2.1969 0.5951 0.4455</code></pre>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The p-value is not significant, so we</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># can accept the null (simpler model)</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ X2 + X4, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4900 -1.4021 -0.1473  1.3871  4.3194 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.46667    0.91941   2.683 0.010847 *  
X2          -0.25788    0.07077  -3.644 0.000819 ***
X4           1.69901    0.10683  15.904  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.911 on 37 degrees of freedom
Multiple R-squared:  0.8873,    Adjusted R-squared:  0.8812 
F-statistic: 145.6 on 2 and 37 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove X2 and check</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">=</span> <span class="fu">update</span>(m3, .<span class="sc">~</span>. <span class="sc">-</span>X2)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m4, m3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ X4
Model 2: y ~ X2 + X4
  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
1     38 183.58                                  
2     37 135.10  1    48.478 13.277 0.0008195 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ok now the p-value is significant</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We need to reject the null (simpler model)</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We *cannot* reliably remove X2</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Try X4 just in case:</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>m5 <span class="ot">=</span> <span class="fu">update</span>(m3, .<span class="sc">~</span>. <span class="sc">-</span>X4)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m3, m5)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Model 1: y ~ X2 + X4
Model 2: y ~ X2
  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    
1     37  135.1                                  
2     38 1058.6 -1   -923.53 252.92 &lt; 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># p-value is significant again</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co"># need to reject the null</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># we cannot drop X4</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Therefore, m3 is most parsimonious</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ X2 + X4, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4900 -1.4021 -0.1473  1.3871  4.3194 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.46667    0.91941   2.683 0.010847 *  
X2          -0.25788    0.07077  -3.644 0.000819 ***
X4           1.69901    0.10683  15.904  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.911 on 37 degrees of freedom
Multiple R-squared:  0.8873,    Adjusted R-squared:  0.8812 
F-statistic: 145.6 on 2 and 37 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>Therefore, model 3, is the minimum acceptable model: <span class="math display">\[y_i = \beta_0 + \beta_2 x_{2,i} + \beta_4 x_{4,i} + \epsilon_i\]</span></p>
<p>We could actually come to the same result, using a different, more automated function, <code>step()</code>. However, this function uses a different metric to test the null vs.&nbsp;full model hypothesis, the Akaike nformation criterion (AIC), which is calculated as: <span class="math display">\[\text{AIC} = - 2ln(\text{Model Likelihood}) + 2k\]</span> And <span class="math inline">\(k\)</span> is the number of estimated parameters in the model. We can then compare the AIC values to decide which models are “best”. We will learn more about AIC later.</p>
<p>Let’s use the <code>step()</code> function and verify it gives us the same final outcome.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>m1_step <span class="ot">=</span> <span class="fu">step</span>(m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Start:  AIC=57.68
y ~ 1 + X1 + X2 + X3 + X4

       Df Sum of Sq     RSS     AIC
- X3    1      1.17  132.90  56.030
- X1    1      2.73  134.46  56.497
&lt;none&gt;               131.73  57.676
- X2    1     51.48  183.22  68.871
- X4    1    870.38 1002.11 136.839

Step:  AIC=56.03
y ~ X1 + X2 + X4

       Df Sum of Sq     RSS     AIC
- X1    1      2.20  135.10  54.686
&lt;none&gt;               132.90  56.030
- X2    1     50.39  183.29  66.888
- X4    1    869.43 1002.34 134.848

Step:  AIC=54.69
y ~ X2 + X4

       Df Sum of Sq     RSS     AIC
&lt;none&gt;               135.10  54.686
- X2    1     48.48  183.58  64.951
- X4    1    923.53 1058.63 135.034</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1_step)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ X2 + X4, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.4900 -1.4021 -0.1473  1.3871  4.3194 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.46667    0.91941   2.683 0.010847 *  
X2          -0.25788    0.07077  -3.644 0.000819 ***
X4           1.69901    0.10683  15.904  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.911 on 37 degrees of freedom
Multiple R-squared:  0.8873,    Adjusted R-squared:  0.8812 
F-statistic: 145.6 on 2 and 37 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>We can see the selected model only includes <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_4\)</span>, just like our decision based on the <span class="math inline">\(F\)</span>-test.</p>
</section>
<section id="model-averaging" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="model-averaging"><span class="header-section-number">7.4</span> Model averaging</h2>
<p>Recall from lecture that model averaging represents another philosophical approach to model selection and model comparison. In this case, the idea is that we cannot know with certainty which model of a nested sub-set of models is “true”. Therefore, instead of reporting the slopes and intercepts from the single “best” model that based on parsimony, we should report “averaged” values of slopes and intercepts. These averages will take into account all of the possible nested subset of models in which those slopes and intercepts could have been calculated. This averaging procedure can produce slope and intercept estimates (as well as estimates of their uncertainty) that are less biased, and can perhaps yield better predictions of future data.</p>
<p>We will use the <code>MuMIn</code> package (Multimodel Inference) to do model averaging later, but first we will do it manually.</p>
<section id="required-calculations" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="required-calculations"><span class="header-section-number">7.4.1</span> Required calculations</h3>
<p>Recall that to come up with averaged estimates of model parameters (e.g., model-averaged slopes) we need to calculate weighted averages. These averages are weighted by how well sub-models explain the data. Following lecture, we will use the corrected <span class="math inline">\(AIC\)</span>, noted as <span class="math inline">\(AIC_c\)</span>, to calculate how well a model explains the data.</p>
<p><span class="math display">\[\text{AIC}_c = - 2ln(\text{Model Likelihood}) + 2k + \frac{2K(K+1)}{n-K-1}\]</span> where <span class="math inline">\(n\)</span> is the number of data observations. Then, to calculate the weights we need to see how much each sub-model deviates from the best model. For this deviation we calculate, for sub-model <span class="math inline">\(i\)</span>:</p>
<p><span class="math display">\[\Delta \text{AIC}_{c,i} = \text{AIC}_{c,\text{best}} - \text{AIC}_{c,i}\]</span> The weight of sub-model <span class="math inline">\(i\)</span> is:</p>
<p><span class="math display">\[w_i = \frac{\text{exp}(-\Delta \text{AIC}_{c,i} / 2)}{\sum_{r=1}^{R} \text{exp}(-\Delta \text{AIC}_{c,r} / 2)} \]</span> And <span class="math inline">\(R\)</span> is the number of submodels being examined.</p>
<p>We are now ready to calculate the weighted average of any parameter of interest in the full model, <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display">\[\hat{\bar{\theta}} = \sum_{r=1}^{R} w_r \hat{\theta}_{r}\]</span> Here, <span class="math inline">\(\hat{\bar{\theta}}\)</span> is the model-averaged estimate of parameter <span class="math inline">\(\theta\)</span>, <span class="math inline">\(w_r\)</span> is the weight of sub-model <span class="math inline">\(r\)</span>, and <span class="math inline">\(\hat{\theta}_r\)</span> is the parameter estimate derived from sub-model <span class="math inline">\(r\)</span>.</p>
<p>We can also calculate the new averaged uncertainty in the parameter estimate:</p>
<p><span class="math display">\[\hat{\text{var}}(\hat{\bar{\theta}}) =  \sum_{r=1}^{R} w_r \left( \hat{\text{var}}(\hat{\theta})_r + (\hat{\theta} - \hat{\bar{\theta}})^2 \right) \]</span> Here, <span class="math inline">\(\hat{\text{var}}(\hat{\bar{\theta}})\)</span> is the standard error of the averaged model parameter, whereas <span class="math inline">\(\hat{\text{var}}(\hat{\theta})_r\)</span> is the standard error of model parameter <span class="math inline">\(\theta\)</span> estimated from sub-model <span class="math inline">\(r\)</span>.</p>
</section>
<section id="manual-calculation" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="manual-calculation"><span class="header-section-number">7.4.2</span> Manual calculation</h3>
<p>Let’s see if we can manually calculate all of this from a less complex example model. Imagine our full model is a model that only has two input variables. We’ll use our simulated data set from above. (Of course, we know this is a poor model, but we’re just doing a case-study here.)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Full model:</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>full_mod <span class="ot">=</span> <span class="fu">lm</span>(y<span class="sc">~</span><span class="dv">1</span><span class="sc">+</span>X1<span class="sc">+</span>X2, <span class="at">data =</span> my_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If this full model has two inputs, then the number of sub-models is <span class="math inline">\(2^2 = 4\)</span>, which iteratively drop one or both input variables. Now, run each sub-model. I know, this is tedious.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>sub_m2 <span class="ot">=</span> <span class="fu">update</span>(full_mod, .<span class="sc">~</span>. <span class="sc">-</span>X2)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>sub_m3 <span class="ot">=</span> <span class="fu">update</span>(full_mod, .<span class="sc">~</span>. <span class="sc">-</span>X1)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>sub_m4 <span class="ot">=</span> <span class="fu">update</span>(full_mod, .<span class="sc">~</span>. <span class="sc">-</span>X2<span class="sc">-</span>X1) <span class="co"># Intercept only</span></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Store all models in a list for easy looping later:</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>model_list <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    full_mod, sub_m2, sub_m3, sub_m4</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a><span class="co"># how many models?</span></span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>n_mod <span class="ot">=</span> <span class="dv">4</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To get the model-averaged slopes of inputs <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, we’ll need to calculate <span class="math inline">\(AIC_c\)</span> values and model weights. We’ll store calculations in arrays as much as possible, so we can loop through.</p>
<p>Let’s start with <span class="math inline">\(AIC_c\)</span>. Fortunately, there’s a built-in function for this in the <code>MuMIn</code> package, but we’ll do one manually first.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract neg-log-likelihood from full model:</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>nll_full <span class="ot">=</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">*</span><span class="fu">logLik</span>(full_mod)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="co"># This is in a weird format, so we'll convert:</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>nll_full <span class="ot">=</span> <span class="fu">as.numeric</span>(nll_full)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>k_full <span class="ot">=</span> <span class="dv">4</span> <span class="co"># two slopes + 1 intercept + residual sigma</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate AIC_c</span></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>aic_c_full <span class="ot">=</span> <span class="dv">2</span><span class="sc">*</span>nll_full <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>k_full <span class="sc">+</span> (<span class="dv">2</span><span class="sc">*</span>k_full<span class="sc">*</span>(k_full <span class="sc">+</span> <span class="dv">1</span>))<span class="sc">/</span>(n <span class="sc">-</span> k_full <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>aic_c_full</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 251.5063</code></pre>
</div>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check with built-in</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MuMIn)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="fu">AICc</span>(full_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 251.5063</code></pre>
</div>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now calculate all:</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>AICc_vec <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_mod){</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    AICc_vec[i] <span class="ot">=</span> <span class="fu">AICc</span>(model_list[[i]])</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>AICc_vec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 251.5063 252.3124 251.2157 253.8381</code></pre>
</div>
</div>
<p>We can see that the ‘best’ model, according to <span class="math inline">\(AIC_c\)</span> is the <code>sub_m3</code>, which includes the intercept and only input <span class="math inline">\(x_2\)</span>. This makes sense, because we know that the slope of <span class="math inline">\(x_1\)</span> was simulated as zero.</p>
<p>Let’s now calculate the <span class="math inline">\(\Delta \text{AIC}_c\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Best AICc</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>AICc_best <span class="ot">=</span> <span class="fu">min</span>(AICc_vec)</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co">#\Delta AIC_c</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>Delta_AICc_vec <span class="ot">=</span> AICc_vec <span class="sc">-</span> AICc_best</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>Delta_AICc_vec</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.290611 1.096742 0.000000 2.622409</code></pre>
</div>
</div>
<p>Now we can calculate the model weights (i.e., the value representing how “good” each model is, relative to the best model).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the denominator of the weight calculation</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>weight_denom <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_mod){</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    weight_denom <span class="ot">=</span> </span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>        weight_denom <span class="sc">+</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">exp</span>( <span class="sc">-</span>Delta_AICc_vec[i] <span class="sc">/</span> <span class="dv">2</span> )</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>weight_denom</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.712144</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now the individual weights:</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>weight <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_mod){</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    weight[i] <span class="ot">=</span> </span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">exp</span>( <span class="sc">-</span>Delta_AICc_vec[i] <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">/</span> weight_denom</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.31884668 0.21307516 0.36871201 0.09936614</code></pre>
</div>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum to 1?</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(weight)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
<p>We can see the “better” models, based on <span class="math inline">\(AIC_c\)</span> have higher weights, and the <code>weight</code> vector should add to 1.</p>
<p>Let’s calculate the model-averaged slope estimate for input <span class="math inline">\(x_2\)</span>. To do this, we’ll first need to extract the estimate from each sub-model. This is a little tedious, because we need to know which coefficient refers to <span class="math inline">\(x_2\)</span> in each sub-model object (or if the coefficient is absent and therefore equal to zero).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>coef_x2 <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>coef_x2[<span class="dv">1</span>] <span class="ot">=</span> <span class="fu">coef</span>(model_list[[<span class="dv">1</span>]])[<span class="dv">3</span>]</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>coef_x2[<span class="dv">2</span>] <span class="ot">=</span> <span class="dv">0</span> <span class="co"># Absent from this sub-model</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>coef_x2[<span class="dv">3</span>] <span class="ot">=</span> <span class="fu">coef</span>(model_list[[<span class="dv">3</span>]])[<span class="dv">2</span>]</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>coef_x2[<span class="dv">4</span>] <span class="ot">=</span> <span class="dv">0</span> <span class="co"># Absent from this sub-model</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>coef_x2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2975017 0.0000000 0.3649074 0.0000000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Averaged, based on model weight:</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>avg_coef_x2 <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_mod){</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    avg_coef_x2 <span class="ot">=</span> </span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>        avg_coef_x2 <span class="sc">+</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>        weight[i] <span class="sc">*</span> coef_x2[i]</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>avg_coef_x2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2294032</code></pre>
</div>
</div>
<p>We can see the model-averaged slope estimate for input <span class="math inline">\(x_2\)</span> is slightly less than the estimate from the full model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(full_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ 1 + X1 + X2, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-9.9147 -3.6749  0.6359  3.4050 10.5608 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 12.58750    1.78926   7.035 2.55e-08 ***
X1           0.14204    0.09854   1.441   0.1579    
X2           0.29750    0.16725   1.779   0.0835 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 5.205 on 37 degrees of freedom
Multiple R-squared:  0.1637,    Adjusted R-squared:  0.1185 
F-statistic: 3.621 on 2 and 37 DF,  p-value: 0.03662</code></pre>
</div>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(full_mod)[<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       X2 
0.2975017 </code></pre>
</div>
</div>
<p>I’ll leave calculating the model-averaged standard error of the slopes as an exercise for you as a student.</p>
<p>As I mentioned above, fortunately someone created a package to do this model averaging for us and remove a lot of the tedium.</p>
<p>First, run all sub-models using the <code>MuMIn::dredge()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Required for MuMIn::dredge functionality</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">na.action =</span> <span class="st">"na.fail"</span>)</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit all sub-models:</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>dredge_test <span class="ot">=</span> <span class="fu">dredge</span>(full_mod)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Fixed term is "(Intercept)"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>dredge_test</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Global model call: lm(formula = y ~ 1 + X1 + X2, data = my_df)
---
Model selection table 
  (Intrc)    X1     X2 df   logLik  AICc delta weight
3   12.71       0.3649  3 -122.275 251.2  0.00  0.369
4   12.59 0.142 0.2975  4 -121.182 251.5  0.29  0.319
2   15.26 0.191         3 -122.823 252.3  1.10  0.213
1   16.31               2 -124.757 253.8  2.62  0.099
Models ranked by AICc(x) </code></pre>
</div>
</div>
<p>See how this output has run all sub-models, calculated the likelihoods, the <span class="math inline">\(AIC_c\)</span>, the <span class="math inline">\(\Delta AIC_c\)</span>, and the model weights.</p>
<p>Now, we can average all of the models.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Average the models:</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>test_average <span class="ot">=</span> <span class="fu">model.avg</span>(dredge_test, <span class="at">fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(test_average)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
model.avg(object = get.models(object = dredge_test, subset = NA))

Component model call: 
lm(formula = y ~ &lt;4 unique rhs&gt;, data = my_df)

Component models: 
       df  logLik   AICc delta weight
2       3 -122.27 251.22  0.00   0.37
12      4 -121.18 251.51  0.29   0.32
1       3 -122.82 252.31  1.10   0.21
(Null)  2 -124.76 253.84  2.62   0.10

Term codes: 
X1 X2 
 1  2 

Model-averaged coefficients:  
(full average) 
            Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    
(Intercept)  13.5710     2.1113      2.1512   6.308   &lt;2e-16 ***
X2            0.2294     0.2083      0.2113   1.086    0.278    
X1            0.0860     0.1092      0.1108   0.776    0.438    
 
(conditional average) 
            Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    
(Intercept)  13.5710     2.1113      2.1512   6.308   &lt;2e-16 ***
X2            0.3336     0.1683      0.1737   1.921   0.0547 .  
X1            0.1617     0.1009      0.1041   1.553   0.1205    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>This <code>summary()</code> statement shows the model-averaged values of slopes of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, and the intercept. We care about the “full average”. You can see the averaged estimate of the slope for <span class="math inline">\(x_2\)</span> matches our manual calculation. For emphasis:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a>test_average<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">2</span>];</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2294032</code></pre>
</div>
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a>avg_coef_x2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2294032</code></pre>
</div>
</div>
</section>
<section id="back-to-more-complex-model" class="level3" data-number="7.4.3">
<h3 data-number="7.4.3" class="anchored" data-anchor-id="back-to-more-complex-model"><span class="header-section-number">7.4.3</span> Back to more complex model</h3>
<p>Ok, but our full model had four input variables, which means the number of sub-models is <span class="math inline">\(4^2 = 16\)</span>. Let’s not do that manually, but instead use the <code>MuMIn::model.avg()</code> function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reminder, m1 was our full model:</span></span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ 1 + X1 + X2 + X3 + X4, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3257 -1.4053 -0.4331  1.3299  4.3178 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  3.41757    1.82632   1.871  0.06968 .  
X1           0.03245    0.03810   0.852  0.40016    
X2          -0.26989    0.07297  -3.698  0.00074 ***
X3          -0.01823    0.03267  -0.558  0.58050    
X4           1.68543    0.11083  15.207  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.94 on 35 degrees of freedom
Multiple R-squared:  0.8901,    Adjusted R-squared:  0.8775 
F-statistic: 70.86 on 4 and 35 DF,  p-value: 2.741e-16</code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit all sub-models:</span></span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>dredge_m1 <span class="ot">=</span> <span class="fu">dredge</span>(m1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Fixed term is "(Intercept)"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Average the models:</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a>m1_average <span class="ot">=</span> <span class="fu">model.avg</span>(dredge_m1, <span class="at">fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1_average)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
model.avg(object = get.models(object = dredge_m1, subset = NA))

Component model call: 
lm(formula = y ~ &lt;16 unique rhs&gt;, data = my_df)

Component models: 
       df  logLik   AICc delta weight
24      4  -81.10 171.34  0.00   0.56
124     5  -80.77 173.31  1.97   0.21
234     5  -81.01 173.78  2.43   0.17
1234    6  -80.60 175.74  4.39   0.06
4       3  -87.23 181.13  9.79   0.00
14      4  -87.20 183.55 12.20   0.00
34      4  -87.23 183.60 12.26   0.00
134     5  -87.19 186.15 14.81   0.00
2       3 -122.27 251.22 79.87   0.00
12      4 -121.18 251.51 80.16   0.00
1       3 -122.82 252.31 80.97   0.00
23      4 -122.21 253.55 82.21   0.00
(Null)  2 -124.76 253.84 82.49   0.00
123     5 -121.18 254.12 82.78   0.00
13      4 -122.82 254.78 83.44   0.00
3       3 -124.73 256.12 84.77   0.00

Term codes: 
X1 X2 X3 X4 
 1  2  3  4 

Model-averaged coefficients:  
(full average) 
             Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    
(Intercept)  2.642223   1.219137    1.258700   2.099 0.035802 *  
X2          -0.258803   0.074396    0.076727   3.373 0.000743 ***
X4           1.693799   0.109648    0.113293  14.951  &lt; 2e-16 ***
X1           0.007999   0.023509    0.024078   0.332 0.739716    
X3          -0.003320   0.016617    0.017119   0.194 0.846219    
 
(conditional average) 
            Estimate Std. Error Adjusted SE z value Pr(&gt;|z|)    
(Intercept)  2.64222    1.21914     1.25870   2.099 0.035802 *  
X2          -0.26062    0.07141     0.07385   3.529 0.000417 ***
X4           1.69380    0.10965     0.11329  14.951  &lt; 2e-16 ***
X1           0.02940    0.03744     0.03875   0.759 0.448057    
X3          -0.01452    0.03232     0.03345   0.434 0.664272    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Notice how we see the model with inputs <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_4\)</span> is the best, based on <span class="math inline">\(AIC_c\)</span> (note this is the model labeled as <code>24</code> meaning it inclues inputs 2 and 4).</p>
<p>We can also plot the model parameter estimates with their confidence intervals:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the coefficient estimates (from the averaged model)</span></span>
<span id="cb76-2"><a href="#cb76-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m1_average)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="model-select_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Finally, we can use the <code>predict()</code> function as we have before to visualize the effect of each input variable on the outcome. Here, we will show the independent, model-averaged effect of <span class="math inline">\(x_2\)</span>, when all other input variables are held at their average values. Then, we’ll do the same for <span class="math inline">\(x_4\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict from the average model:</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="co"># How does y change as a function of x2, while </span></span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a><span class="co"># other inputs held at their average?</span></span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>new_df <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">X1 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X1), <span class="dv">100</span>),</span>
<span id="cb77-6"><a href="#cb77-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">X2 =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">19</span>, <span class="at">length.out =</span> <span class="dv">100</span>),</span>
<span id="cb77-7"><a href="#cb77-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">X3 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X3), <span class="dv">100</span>),</span>
<span id="cb77-8"><a href="#cb77-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">X4 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X4), <span class="dv">100</span>)</span>
<span id="cb77-9"><a href="#cb77-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb77-10"><a href="#cb77-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-11"><a href="#cb77-11" aria-hidden="true" tabindex="-1"></a>pred_m1_avg_x2 <span class="ot">=</span> </span>
<span id="cb77-12"><a href="#cb77-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(m1_average,</span>
<span id="cb77-13"><a href="#cb77-13" aria-hidden="true" tabindex="-1"></a>            <span class="at">newdata =</span> new_df,</span>
<span id="cb77-14"><a href="#cb77-14" aria-hidden="true" tabindex="-1"></a>            <span class="at">se.fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb77-15"><a href="#cb77-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb77-16"><a href="#cb77-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> my_df<span class="sc">$</span>X2,</span>
<span id="cb77-17"><a href="#cb77-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"input x2"</span>, <span class="at">ylab =</span> <span class="st">"y"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb77-18"><a href="#cb77-18" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x2<span class="sc">$</span>fit <span class="sc">~</span> new_df<span class="sc">$</span>X2)</span>
<span id="cb77-19"><a href="#cb77-19" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x2<span class="sc">$</span>fit<span class="dv">-2</span><span class="sc">*</span>pred_m1_avg_x2<span class="sc">$</span>se.fit <span class="sc">~</span> new_df<span class="sc">$</span>X2, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb77-20"><a href="#cb77-20" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x2<span class="sc">$</span>fit<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>pred_m1_avg_x2<span class="sc">$</span>se.fit <span class="sc">~</span> new_df<span class="sc">$</span>X2, <span class="at">lty =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="model-select_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict from the average model:</span></span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="co"># How does y change as a function of x4, while </span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="co"># other inputs held at their average?</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>new_df <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">X1 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X1), <span class="dv">100</span>),</span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">X2 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X2), <span class="dv">100</span>),</span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">X3 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X3), <span class="dv">100</span>),</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">X4 =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">19</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>pred_m1_avg_x4 <span class="ot">=</span> </span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(m1_average,</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>            <span class="at">newdata =</span> new_df,</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a>            <span class="at">se.fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-16"><a href="#cb78-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> my_df<span class="sc">$</span>X4,</span>
<span id="cb78-17"><a href="#cb78-17" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"input x4"</span>, <span class="at">ylab =</span> <span class="st">"y"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb78-18"><a href="#cb78-18" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x4<span class="sc">$</span>fit <span class="sc">~</span> new_df<span class="sc">$</span>X4)</span>
<span id="cb78-19"><a href="#cb78-19" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x4<span class="sc">$</span>fit<span class="dv">-2</span><span class="sc">*</span>pred_m1_avg_x4<span class="sc">$</span>se.fit <span class="sc">~</span> new_df<span class="sc">$</span>X4, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb78-20"><a href="#cb78-20" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x4<span class="sc">$</span>fit<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>pred_m1_avg_x4<span class="sc">$</span>se.fit <span class="sc">~</span> new_df<span class="sc">$</span>X4, <span class="at">lty =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="model-select_files/figure-html/unnamed-chunk-18-2.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Another, perhaps simpler way to vizualize how well a model matches the data is to plot the model predictions of the data versus the observed data. We can even compare this to the non-averaged model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>raw_predict_avg <span class="ot">=</span> <span class="fu">predict</span>(m1_average)</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a>raw_predict_nonavg <span class="ot">=</span> <span class="fu">predict</span>(m1)</span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>raw_predict_bad <span class="ot">=</span> <span class="fu">predict</span>(sub_m2)</span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> raw_predict_avg,</span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Model Prediction"</span>, <span class="at">ylab =</span> <span class="st">"Data, y"</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> raw_predict_nonavg, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"black"</span>)</span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> raw_predict_bad, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"orange"</span>)</span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 1-to-1 line</span></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="model-select_files/figure-html/unnamed-chunk-19-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>It is hard to see, and likely not significant in this case, but the red points (model-averaged) tend to be closer to the 1:1 line, compared to the black points, meaning the averaged model makes slightly better predictions of the observed data. What is more clear, is that the “bad” model (which only included covariate <span class="math inline">\(x_1\)</span>), does not match the 1:1 line at all; it’s more of a shot-gun of points. Therefore, this clearly indicates the model is not predictive of the <span class="math inline">\(y\)</span> data. This is a good visualization of how well your models’ within-sample prediction (i.e., how close the model predictions of observed data match the observed data).</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./max-lik.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./anova.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">ANOVA</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb80" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Model selection {#sec-modelselect}</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="fu">## Lecture material</span></span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-5"><a href="#cb80-5" aria-hidden="true" tabindex="-1"></a>Please download and print the lecture materials from <span class="co">[</span><span class="ot">Bblearn</span><span class="co">](https://bblearn.nau.edu/)</span>{target="_blank"}. After lectures, the recordings will appear in the Bblearn Collaborate Ultra section.</span>
<span id="cb80-6"><a href="#cb80-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-7"><a href="#cb80-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## Generate the data {#sec-data}</span></span>
<span id="cb80-8"><a href="#cb80-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-9"><a href="#cb80-9" aria-hidden="true" tabindex="-1"></a>Here we will demonstrate two approaches to model comparison. But first let's generate data, in the same way we did for multiple linear regression in (@sec-ols). Note that in this case, we will specify that two of the input variables have zero slope (i.e., no linear association with the outcome variable).</span>
<span id="cb80-10"><a href="#cb80-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-13"><a href="#cb80-13" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-14"><a href="#cb80-14" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">40</span></span>
<span id="cb80-15"><a href="#cb80-15" aria-hidden="true" tabindex="-1"></a>n_covariate <span class="ot">=</span> <span class="dv">4</span></span>
<span id="cb80-16"><a href="#cb80-16" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> n_covariate <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb80-17"><a href="#cb80-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-18"><a href="#cb80-18" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">=</span> <span class="fu">vector</span>(<span class="st">"numeric"</span>, <span class="at">length =</span> p)</span>
<span id="cb80-19"><a href="#cb80-19" aria-hidden="true" tabindex="-1"></a>xmat <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n, <span class="at">ncol =</span> p)</span>
<span id="cb80-20"><a href="#cb80-20" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fl">2.25</span></span>
<span id="cb80-21"><a href="#cb80-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-22"><a href="#cb80-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Column for intercept</span></span>
<span id="cb80-23"><a href="#cb80-23" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">1</span>] <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb80-24"><a href="#cb80-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-25"><a href="#cb80-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the covariate data randomly:</span></span>
<span id="cb80-26"><a href="#cb80-26" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5</span>)</span>
<span id="cb80-27"><a href="#cb80-27" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">2</span>] <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">8</span>)</span>
<span id="cb80-28"><a href="#cb80-28" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">3</span>] <span class="ot">=</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">20</span>)</span>
<span id="cb80-29"><a href="#cb80-29" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">4</span>] <span class="ot">=</span> <span class="fu">rchisq</span>(n, <span class="at">df =</span> <span class="dv">50</span>)</span>
<span id="cb80-30"><a href="#cb80-30" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">5</span>] <span class="ot">=</span> <span class="fu">rpois</span>(n, <span class="at">lambda =</span> <span class="dv">10</span>)</span>
<span id="cb80-31"><a href="#cb80-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-32"><a href="#cb80-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the betas:</span></span>
<span id="cb80-33"><a href="#cb80-33" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">1</span>] <span class="ot">=</span> <span class="fl">1.0</span></span>
<span id="cb80-34"><a href="#cb80-34" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">2</span>] <span class="ot">=</span> <span class="fl">0.0</span></span>
<span id="cb80-35"><a href="#cb80-35" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">3</span>] <span class="ot">=</span> <span class="sc">-</span><span class="fl">0.2</span></span>
<span id="cb80-36"><a href="#cb80-36" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">4</span>] <span class="ot">=</span> <span class="fl">0.0</span></span>
<span id="cb80-37"><a href="#cb80-37" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">5</span>] <span class="ot">=</span> <span class="fl">1.8</span></span>
<span id="cb80-38"><a href="#cb80-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-39"><a href="#cb80-39" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the observed 'y', adding residual error</span></span>
<span id="cb80-40"><a href="#cb80-40" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> xmat <span class="sc">%*%</span> betas <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb80-41"><a href="#cb80-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-42"><a href="#cb80-42" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb80-43"><a href="#cb80-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>p){</span>
<span id="cb80-44"><a href="#cb80-44" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(y <span class="sc">~</span> xmat[,i],</span>
<span id="cb80-45"><a href="#cb80-45" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="fu">paste</span>(<span class="st">"covariate "</span>, i<span class="dv">-1</span>))</span>
<span id="cb80-46"><a href="#cb80-46" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb80-47"><a href="#cb80-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-48"><a href="#cb80-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data.frame</span></span>
<span id="cb80-49"><a href="#cb80-49" aria-hidden="true" tabindex="-1"></a>my_df <span class="ot">=</span> <span class="fu">data.frame</span>(y, xmat[,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb80-50"><a href="#cb80-50" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(my_df)</span>
<span id="cb80-51"><a href="#cb80-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-52"><a href="#cb80-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the model, report the summary</span></span>
<span id="cb80-53"><a href="#cb80-53" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3 <span class="sc">+</span> X4, <span class="at">data =</span> my_df)</span>
<span id="cb80-54"><a href="#cb80-54" aria-hidden="true" tabindex="-1"></a>m1_summary <span class="ot">=</span> <span class="fu">summary</span>(m1)</span>
<span id="cb80-55"><a href="#cb80-55" aria-hidden="true" tabindex="-1"></a>m1_summary</span>
<span id="cb80-56"><a href="#cb80-56" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-57"><a href="#cb80-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-58"><a href="#cb80-58" aria-hidden="true" tabindex="-1"></a><span class="fu">## Parsimony via model simplification</span></span>
<span id="cb80-59"><a href="#cb80-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-60"><a href="#cb80-60" aria-hidden="true" tabindex="-1"></a>We will successively simplify the model until we find a "minimally acceptable" model that explains the most variability in the outcome variable. </span>
<span id="cb80-61"><a href="#cb80-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-62"><a href="#cb80-62" aria-hidden="true" tabindex="-1"></a>There are several built-in functions in R that can help us make quantitatively justified decisions about which input variables can be dropped from the full model to determine our minimally acceptable model. First, we can use the $F$-test as described in lecture. This can be implemented by the <span class="in">`anova()`</span> function. </span>
<span id="cb80-63"><a href="#cb80-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-64"><a href="#cb80-64" aria-hidden="true" tabindex="-1"></a>Based on the <span class="in">`summary()`</span> output, we see that input variable 3 ($x_3$) has the least significant effect on $y$, so we will drop that first and proceed from there. </span>
<span id="cb80-65"><a href="#cb80-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-68"><a href="#cb80-68" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-69"><a href="#cb80-69" aria-hidden="true" tabindex="-1"></a><span class="co"># The full model lives in object m1</span></span>
<span id="cb80-70"><a href="#cb80-70" aria-hidden="true" tabindex="-1"></a><span class="fu">formula</span>(m1)</span>
<span id="cb80-71"><a href="#cb80-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-72"><a href="#cb80-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a new model with the update() function</span></span>
<span id="cb80-73"><a href="#cb80-73" aria-hidden="true" tabindex="-1"></a><span class="co"># This function has a strange notation, but so it goes...</span></span>
<span id="cb80-74"><a href="#cb80-74" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">=</span> <span class="fu">update</span>(m1, .<span class="sc">~</span>. <span class="sc">-</span>X3)</span>
<span id="cb80-75"><a href="#cb80-75" aria-hidden="true" tabindex="-1"></a><span class="fu">formula</span>(m2)</span>
<span id="cb80-76"><a href="#cb80-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-77"><a href="#cb80-77" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m2)</span>
<span id="cb80-78"><a href="#cb80-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-79"><a href="#cb80-79" aria-hidden="true" tabindex="-1"></a><span class="co"># Use anova() to test if the drop of X3 is justified</span></span>
<span id="cb80-80"><a href="#cb80-80" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m2, m1)</span>
<span id="cb80-81"><a href="#cb80-81" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-82"><a href="#cb80-82" aria-hidden="true" tabindex="-1"></a>Remember that the hypothesis tested is:</span>
<span id="cb80-83"><a href="#cb80-83" aria-hidden="true" tabindex="-1"></a>$$H_0:\text{simple model}$$</span>
<span id="cb80-84"><a href="#cb80-84" aria-hidden="true" tabindex="-1"></a>$$H_A:\text{complex model}$$</span>
<span id="cb80-85"><a href="#cb80-85" aria-hidden="true" tabindex="-1"></a>So if the $p \ge 0.05$, as usual, we cannot reject the null hypothesis. In this case, it means that the simple model is just as good as the more complex model. Therefore, we are justified in dropping $x_3$. From the data, we could not detect that $x_3$ has a statistically meaningful linear relationship with the outcome data $y$. </span>
<span id="cb80-86"><a href="#cb80-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-87"><a href="#cb80-87" aria-hidden="true" tabindex="-1"></a>Let's manually calculate that $F$ test statistic and associated $p$-value to verify that we understand how the test works. </span>
<span id="cb80-88"><a href="#cb80-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-91"><a href="#cb80-91" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-92"><a href="#cb80-92" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the residuals (errors)</span></span>
<span id="cb80-93"><a href="#cb80-93" aria-hidden="true" tabindex="-1"></a>resid_null <span class="ot">=</span> m2<span class="sc">$</span>residuals</span>
<span id="cb80-94"><a href="#cb80-94" aria-hidden="true" tabindex="-1"></a>resid_full <span class="ot">=</span> m1<span class="sc">$</span>residuals</span>
<span id="cb80-95"><a href="#cb80-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-96"><a href="#cb80-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of Square Errors (SSE)</span></span>
<span id="cb80-97"><a href="#cb80-97" aria-hidden="true" tabindex="-1"></a>sse_null <span class="ot">=</span> <span class="fu">crossprod</span>(resid_null)</span>
<span id="cb80-98"><a href="#cb80-98" aria-hidden="true" tabindex="-1"></a>sse_full <span class="ot">=</span> <span class="fu">crossprod</span>(resid_full)</span>
<span id="cb80-99"><a href="#cb80-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-100"><a href="#cb80-100" aria-hidden="true" tabindex="-1"></a><span class="co"># degrees of freedom</span></span>
<span id="cb80-101"><a href="#cb80-101" aria-hidden="true" tabindex="-1"></a>df_null <span class="ot">=</span> n<span class="sc">-</span>(p<span class="dv">-1</span>) <span class="co"># we dropped one input variable</span></span>
<span id="cb80-102"><a href="#cb80-102" aria-hidden="true" tabindex="-1"></a>df_full <span class="ot">=</span> n<span class="sc">-</span>p</span>
<span id="cb80-103"><a href="#cb80-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-104"><a href="#cb80-104" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate F_stat</span></span>
<span id="cb80-105"><a href="#cb80-105" aria-hidden="true" tabindex="-1"></a>f_test <span class="ot">=</span> ((sse_null <span class="sc">-</span> sse_full)<span class="sc">/</span>(df_null <span class="sc">-</span> df_full)) <span class="sc">/</span> (sse_full<span class="sc">/</span>df_full)</span>
<span id="cb80-106"><a href="#cb80-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-107"><a href="#cb80-107" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of freedom for the F distribution:</span></span>
<span id="cb80-108"><a href="#cb80-108" aria-hidden="true" tabindex="-1"></a>df_numerator <span class="ot">=</span> df_null <span class="sc">-</span> df_full</span>
<span id="cb80-109"><a href="#cb80-109" aria-hidden="true" tabindex="-1"></a>df_denominator <span class="ot">=</span> df_full</span>
<span id="cb80-110"><a href="#cb80-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-111"><a href="#cb80-111" aria-hidden="true" tabindex="-1"></a>p_m1vm2 <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pf</span>(f_test,</span>
<span id="cb80-112"><a href="#cb80-112" aria-hidden="true" tabindex="-1"></a>                <span class="at">df1 =</span> df_numerator,</span>
<span id="cb80-113"><a href="#cb80-113" aria-hidden="true" tabindex="-1"></a>                <span class="at">df2 =</span> df_denominator)</span>
<span id="cb80-114"><a href="#cb80-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-115"><a href="#cb80-115" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to anova()</span></span>
<span id="cb80-116"><a href="#cb80-116" aria-hidden="true" tabindex="-1"></a>f_test; p_m1vm2</span>
<span id="cb80-117"><a href="#cb80-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-118"><a href="#cb80-118" aria-hidden="true" tabindex="-1"></a>anova_m1vm2 <span class="ot">=</span> <span class="fu">anova</span>(m2,m1)</span>
<span id="cb80-119"><a href="#cb80-119" aria-hidden="true" tabindex="-1"></a>anova_m1vm2<span class="sc">$</span><span class="st">`</span><span class="at">F</span><span class="st">`</span>; anova_m1vm2<span class="sc">$</span><span class="st">`</span><span class="at">Pr(&gt;F)</span><span class="st">`</span></span>
<span id="cb80-120"><a href="#cb80-120" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-121"><a href="#cb80-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-122"><a href="#cb80-122" aria-hidden="true" tabindex="-1"></a>Let's continue with the simplification process, using the <span class="in">`anova()`</span> function.</span>
<span id="cb80-123"><a href="#cb80-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-126"><a href="#cb80-126" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-127"><a href="#cb80-127" aria-hidden="true" tabindex="-1"></a><span class="co"># model 2 is the current best.</span></span>
<span id="cb80-128"><a href="#cb80-128" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m2)</span>
<span id="cb80-129"><a href="#cb80-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-130"><a href="#cb80-130" aria-hidden="true" tabindex="-1"></a><span class="co"># Now, drop x1 and check</span></span>
<span id="cb80-131"><a href="#cb80-131" aria-hidden="true" tabindex="-1"></a>m3 <span class="ot">=</span> <span class="fu">update</span>(m2, .<span class="sc">~</span>. <span class="sc">-</span>X1)</span>
<span id="cb80-132"><a href="#cb80-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-133"><a href="#cb80-133" aria-hidden="true" tabindex="-1"></a><span class="co"># Check:</span></span>
<span id="cb80-134"><a href="#cb80-134" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m3, m2)</span>
<span id="cb80-135"><a href="#cb80-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-136"><a href="#cb80-136" aria-hidden="true" tabindex="-1"></a><span class="co"># The p-value is not significant, so we</span></span>
<span id="cb80-137"><a href="#cb80-137" aria-hidden="true" tabindex="-1"></a><span class="co"># can accept the null (simpler model)</span></span>
<span id="cb80-138"><a href="#cb80-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-139"><a href="#cb80-139" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m3)</span>
<span id="cb80-140"><a href="#cb80-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-141"><a href="#cb80-141" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove X2 and check</span></span>
<span id="cb80-142"><a href="#cb80-142" aria-hidden="true" tabindex="-1"></a>m4 <span class="ot">=</span> <span class="fu">update</span>(m3, .<span class="sc">~</span>. <span class="sc">-</span>X2)</span>
<span id="cb80-143"><a href="#cb80-143" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m4, m3)</span>
<span id="cb80-144"><a href="#cb80-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-145"><a href="#cb80-145" aria-hidden="true" tabindex="-1"></a><span class="co"># Ok now the p-value is significant</span></span>
<span id="cb80-146"><a href="#cb80-146" aria-hidden="true" tabindex="-1"></a><span class="co"># We need to reject the null (simpler model)</span></span>
<span id="cb80-147"><a href="#cb80-147" aria-hidden="true" tabindex="-1"></a><span class="co"># We *cannot* reliably remove X2</span></span>
<span id="cb80-148"><a href="#cb80-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-149"><a href="#cb80-149" aria-hidden="true" tabindex="-1"></a><span class="co"># Try X4 just in case:</span></span>
<span id="cb80-150"><a href="#cb80-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-151"><a href="#cb80-151" aria-hidden="true" tabindex="-1"></a>m5 <span class="ot">=</span> <span class="fu">update</span>(m3, .<span class="sc">~</span>. <span class="sc">-</span>X4)</span>
<span id="cb80-152"><a href="#cb80-152" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(m3, m5)</span>
<span id="cb80-153"><a href="#cb80-153" aria-hidden="true" tabindex="-1"></a><span class="co"># p-value is significant again</span></span>
<span id="cb80-154"><a href="#cb80-154" aria-hidden="true" tabindex="-1"></a><span class="co"># need to reject the null</span></span>
<span id="cb80-155"><a href="#cb80-155" aria-hidden="true" tabindex="-1"></a><span class="co"># we cannot drop X4</span></span>
<span id="cb80-156"><a href="#cb80-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-157"><a href="#cb80-157" aria-hidden="true" tabindex="-1"></a><span class="co"># Therefore, m3 is most parsimonious</span></span>
<span id="cb80-158"><a href="#cb80-158" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m3)</span>
<span id="cb80-159"><a href="#cb80-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-160"><a href="#cb80-160" aria-hidden="true" tabindex="-1"></a>Therefore, model 3, is the minimum acceptable model:</span>
<span id="cb80-161"><a href="#cb80-161" aria-hidden="true" tabindex="-1"></a>$$y_i = \beta_0 + \beta_2 x_{2,i} + \beta_4 x_{4,i} + \epsilon_i$$</span>
<span id="cb80-162"><a href="#cb80-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-163"><a href="#cb80-163" aria-hidden="true" tabindex="-1"></a>We could actually come to the same result, using a different, more automated function, <span class="in">`step()`</span>. However, this function uses a different metric to test the null vs. full model hypothesis, the Akaike nformation criterion (AIC), which is calculated as:</span>
<span id="cb80-164"><a href="#cb80-164" aria-hidden="true" tabindex="-1"></a>$$\text{AIC} = - 2ln(\text{Model Likelihood}) + 2k$$</span>
<span id="cb80-165"><a href="#cb80-165" aria-hidden="true" tabindex="-1"></a>And $k$ is the number of estimated parameters in the model. We can then compare the AIC values to decide which models are "best". We will learn more about AIC later.</span>
<span id="cb80-166"><a href="#cb80-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-167"><a href="#cb80-167" aria-hidden="true" tabindex="-1"></a>Let's use the <span class="in">`step()`</span> function and verify it gives us the same final outcome.</span>
<span id="cb80-168"><a href="#cb80-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-171"><a href="#cb80-171" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-172"><a href="#cb80-172" aria-hidden="true" tabindex="-1"></a>m1_step <span class="ot">=</span> <span class="fu">step</span>(m1)</span>
<span id="cb80-173"><a href="#cb80-173" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1_step)</span>
<span id="cb80-174"><a href="#cb80-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-175"><a href="#cb80-175" aria-hidden="true" tabindex="-1"></a>We can see the selected model only includes $x_2$ and $x_4$, just like our decision based on the $F$-test. </span>
<span id="cb80-176"><a href="#cb80-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-177"><a href="#cb80-177" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model averaging</span></span>
<span id="cb80-178"><a href="#cb80-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-179"><a href="#cb80-179" aria-hidden="true" tabindex="-1"></a>Recall from lecture that model averaging represents another philosophical approach to model selection and model comparison. In this case, the idea is that we cannot know with certainty which model of a nested sub-set of models is "true". Therefore, instead of reporting the slopes and intercepts from the single "best" model that based on parsimony, we should report "averaged" values of slopes and intercepts. These averages will take into account all of the possible nested subset of models in which those slopes and intercepts could have been calculated. This averaging procedure can produce slope and intercept estimates (as well as estimates of their uncertainty) that are less biased, and can perhaps yield better predictions of future data. </span>
<span id="cb80-180"><a href="#cb80-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-181"><a href="#cb80-181" aria-hidden="true" tabindex="-1"></a>We will use the <span class="in">`MuMIn`</span> package (Multimodel Inference) to do model averaging later, but first we will do it manually. </span>
<span id="cb80-182"><a href="#cb80-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-183"><a href="#cb80-183" aria-hidden="true" tabindex="-1"></a><span class="fu">### Required calculations</span></span>
<span id="cb80-184"><a href="#cb80-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-185"><a href="#cb80-185" aria-hidden="true" tabindex="-1"></a>Recall that to come up with averaged estimates of model parameters (e.g., model-averaged slopes) we need to calculate weighted averages. These averages are weighted by how well sub-models explain the data. Following lecture, we will use the corrected $AIC$, noted as $AIC_c$, to calculate how well a model explains the data. </span>
<span id="cb80-186"><a href="#cb80-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-187"><a href="#cb80-187" aria-hidden="true" tabindex="-1"></a>$$\text{AIC}_c = - 2ln(\text{Model Likelihood}) + 2k + \frac{2K(K+1)}{n-K-1}$$</span>
<span id="cb80-188"><a href="#cb80-188" aria-hidden="true" tabindex="-1"></a>where $n$ is the number of data observations. Then, to calculate the weights we need to see how much each sub-model deviates from the best model. For this deviation we calculate, for sub-model $i$:</span>
<span id="cb80-189"><a href="#cb80-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-190"><a href="#cb80-190" aria-hidden="true" tabindex="-1"></a>$$\Delta \text{AIC}_{c,i} = \text{AIC}_{c,\text{best}} - \text{AIC}_{c,i}$$</span>
<span id="cb80-191"><a href="#cb80-191" aria-hidden="true" tabindex="-1"></a>The weight of sub-model $i$ is:</span>
<span id="cb80-192"><a href="#cb80-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-193"><a href="#cb80-193" aria-hidden="true" tabindex="-1"></a>$$w_i = \frac{\text{exp}(-\Delta \text{AIC}_{c,i} / 2)}{\sum_{r=1}^{R} \text{exp}(-\Delta \text{AIC}_{c,r} / 2)} $$</span>
<span id="cb80-194"><a href="#cb80-194" aria-hidden="true" tabindex="-1"></a>And $R$ is the number of submodels being examined. </span>
<span id="cb80-195"><a href="#cb80-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-196"><a href="#cb80-196" aria-hidden="true" tabindex="-1"></a>We are now ready to calculate the weighted average of any parameter of interest in the full model, $\theta$:</span>
<span id="cb80-197"><a href="#cb80-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-198"><a href="#cb80-198" aria-hidden="true" tabindex="-1"></a>$$\hat{\bar{\theta}} = \sum_{r=1}^{R} w_r \hat{\theta}_{r}$$</span>
<span id="cb80-199"><a href="#cb80-199" aria-hidden="true" tabindex="-1"></a>Here, $\hat{\bar{\theta}}$ is the model-averaged estimate of parameter $\theta$, $w_r$ is the weight of sub-model $r$, and $\hat{\theta}_r$ is the parameter estimate derived from sub-model $r$. </span>
<span id="cb80-200"><a href="#cb80-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-201"><a href="#cb80-201" aria-hidden="true" tabindex="-1"></a>We can also calculate the new averaged uncertainty in the parameter estimate:</span>
<span id="cb80-202"><a href="#cb80-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-203"><a href="#cb80-203" aria-hidden="true" tabindex="-1"></a>$$\hat{\text{var}}(\hat{\bar{\theta}}) =  \sum_{r=1}^{R} w_r \left( \hat{\text{var}}(\hat{\theta})_r + (\hat{\theta} - \hat{\bar{\theta}})^2 \right) $$</span>
<span id="cb80-204"><a href="#cb80-204" aria-hidden="true" tabindex="-1"></a>Here, $\hat{\text{var}}(\hat{\bar{\theta}})$ is the standard error of the averaged model parameter, whereas $\hat{\text{var}}(\hat{\theta})_r$ is the standard error of model parameter $\theta$ estimated from sub-model $r$. </span>
<span id="cb80-205"><a href="#cb80-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-206"><a href="#cb80-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-207"><a href="#cb80-207" aria-hidden="true" tabindex="-1"></a><span class="fu">### Manual calculation</span></span>
<span id="cb80-208"><a href="#cb80-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-209"><a href="#cb80-209" aria-hidden="true" tabindex="-1"></a>Let's see if we can manually calculate all of this from a less complex example model. Imagine our full model is a model that only has two input variables. We'll use our simulated data set from above. (Of course, we know this is a poor model, but we're just doing a case-study here.)</span>
<span id="cb80-210"><a href="#cb80-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-213"><a href="#cb80-213" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-214"><a href="#cb80-214" aria-hidden="true" tabindex="-1"></a><span class="co"># Full model:</span></span>
<span id="cb80-215"><a href="#cb80-215" aria-hidden="true" tabindex="-1"></a>full_mod <span class="ot">=</span> <span class="fu">lm</span>(y<span class="sc">~</span><span class="dv">1</span><span class="sc">+</span>X1<span class="sc">+</span>X2, <span class="at">data =</span> my_df)</span>
<span id="cb80-216"><a href="#cb80-216" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-217"><a href="#cb80-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-218"><a href="#cb80-218" aria-hidden="true" tabindex="-1"></a>If this full model has two inputs, then the number of sub-models is $2^2 = 4$, which iteratively drop one or both input variables. Now, run each sub-model. I know, this is tedious.</span>
<span id="cb80-219"><a href="#cb80-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-222"><a href="#cb80-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-223"><a href="#cb80-223" aria-hidden="true" tabindex="-1"></a>sub_m2 <span class="ot">=</span> <span class="fu">update</span>(full_mod, .<span class="sc">~</span>. <span class="sc">-</span>X2)</span>
<span id="cb80-224"><a href="#cb80-224" aria-hidden="true" tabindex="-1"></a>sub_m3 <span class="ot">=</span> <span class="fu">update</span>(full_mod, .<span class="sc">~</span>. <span class="sc">-</span>X1)</span>
<span id="cb80-225"><a href="#cb80-225" aria-hidden="true" tabindex="-1"></a>sub_m4 <span class="ot">=</span> <span class="fu">update</span>(full_mod, .<span class="sc">~</span>. <span class="sc">-</span>X2<span class="sc">-</span>X1) <span class="co"># Intercept only</span></span>
<span id="cb80-226"><a href="#cb80-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-227"><a href="#cb80-227" aria-hidden="true" tabindex="-1"></a><span class="co"># Store all models in a list for easy looping later:</span></span>
<span id="cb80-228"><a href="#cb80-228" aria-hidden="true" tabindex="-1"></a>model_list <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb80-229"><a href="#cb80-229" aria-hidden="true" tabindex="-1"></a>    full_mod, sub_m2, sub_m3, sub_m4</span>
<span id="cb80-230"><a href="#cb80-230" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-231"><a href="#cb80-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-232"><a href="#cb80-232" aria-hidden="true" tabindex="-1"></a><span class="co"># how many models?</span></span>
<span id="cb80-233"><a href="#cb80-233" aria-hidden="true" tabindex="-1"></a>n_mod <span class="ot">=</span> <span class="dv">4</span></span>
<span id="cb80-234"><a href="#cb80-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-235"><a href="#cb80-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-236"><a href="#cb80-236" aria-hidden="true" tabindex="-1"></a>To get the model-averaged slopes of inputs $x_1$ and $x_2$, we'll need to calculate $AIC_c$ values and model weights. We'll store calculations in arrays as much as possible, so we can loop through. </span>
<span id="cb80-237"><a href="#cb80-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-238"><a href="#cb80-238" aria-hidden="true" tabindex="-1"></a>Let's start with $AIC_c$. Fortunately, there's a built-in function for this in the <span class="in">`MuMIn`</span> package, but we'll do one manually first. </span>
<span id="cb80-239"><a href="#cb80-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-242"><a href="#cb80-242" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-243"><a href="#cb80-243" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract neg-log-likelihood from full model:</span></span>
<span id="cb80-244"><a href="#cb80-244" aria-hidden="true" tabindex="-1"></a>nll_full <span class="ot">=</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">*</span><span class="fu">logLik</span>(full_mod)</span>
<span id="cb80-245"><a href="#cb80-245" aria-hidden="true" tabindex="-1"></a><span class="co"># This is in a weird format, so we'll convert:</span></span>
<span id="cb80-246"><a href="#cb80-246" aria-hidden="true" tabindex="-1"></a>nll_full <span class="ot">=</span> <span class="fu">as.numeric</span>(nll_full)</span>
<span id="cb80-247"><a href="#cb80-247" aria-hidden="true" tabindex="-1"></a>k_full <span class="ot">=</span> <span class="dv">4</span> <span class="co"># two slopes + 1 intercept + residual sigma</span></span>
<span id="cb80-248"><a href="#cb80-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-249"><a href="#cb80-249" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate AIC_c</span></span>
<span id="cb80-250"><a href="#cb80-250" aria-hidden="true" tabindex="-1"></a>aic_c_full <span class="ot">=</span> <span class="dv">2</span><span class="sc">*</span>nll_full <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>k_full <span class="sc">+</span> (<span class="dv">2</span><span class="sc">*</span>k_full<span class="sc">*</span>(k_full <span class="sc">+</span> <span class="dv">1</span>))<span class="sc">/</span>(n <span class="sc">-</span> k_full <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb80-251"><a href="#cb80-251" aria-hidden="true" tabindex="-1"></a>aic_c_full</span>
<span id="cb80-252"><a href="#cb80-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-253"><a href="#cb80-253" aria-hidden="true" tabindex="-1"></a><span class="co"># Check with built-in</span></span>
<span id="cb80-254"><a href="#cb80-254" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MuMIn)</span>
<span id="cb80-255"><a href="#cb80-255" aria-hidden="true" tabindex="-1"></a><span class="fu">AICc</span>(full_mod)</span>
<span id="cb80-256"><a href="#cb80-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-257"><a href="#cb80-257" aria-hidden="true" tabindex="-1"></a><span class="co"># Now calculate all:</span></span>
<span id="cb80-258"><a href="#cb80-258" aria-hidden="true" tabindex="-1"></a>AICc_vec <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb80-259"><a href="#cb80-259" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_mod){</span>
<span id="cb80-260"><a href="#cb80-260" aria-hidden="true" tabindex="-1"></a>    AICc_vec[i] <span class="ot">=</span> <span class="fu">AICc</span>(model_list[[i]])</span>
<span id="cb80-261"><a href="#cb80-261" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb80-262"><a href="#cb80-262" aria-hidden="true" tabindex="-1"></a>AICc_vec</span>
<span id="cb80-263"><a href="#cb80-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-264"><a href="#cb80-264" aria-hidden="true" tabindex="-1"></a>We can see that the 'best' model, according to $AIC_c$ is the <span class="in">`sub_m3`</span>, which includes the intercept and only input $x_2$. This makes sense, because we know that the slope of $x_1$ was simulated as zero.</span>
<span id="cb80-265"><a href="#cb80-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-266"><a href="#cb80-266" aria-hidden="true" tabindex="-1"></a>Let's now calculate the $\Delta \text{AIC}_c$.</span>
<span id="cb80-267"><a href="#cb80-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-270"><a href="#cb80-270" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-271"><a href="#cb80-271" aria-hidden="true" tabindex="-1"></a><span class="co"># Best AICc</span></span>
<span id="cb80-272"><a href="#cb80-272" aria-hidden="true" tabindex="-1"></a>AICc_best <span class="ot">=</span> <span class="fu">min</span>(AICc_vec)</span>
<span id="cb80-273"><a href="#cb80-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-274"><a href="#cb80-274" aria-hidden="true" tabindex="-1"></a><span class="co">#\Delta AIC_c</span></span>
<span id="cb80-275"><a href="#cb80-275" aria-hidden="true" tabindex="-1"></a>Delta_AICc_vec <span class="ot">=</span> AICc_vec <span class="sc">-</span> AICc_best</span>
<span id="cb80-276"><a href="#cb80-276" aria-hidden="true" tabindex="-1"></a>Delta_AICc_vec</span>
<span id="cb80-277"><a href="#cb80-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-278"><a href="#cb80-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-279"><a href="#cb80-279" aria-hidden="true" tabindex="-1"></a>Now we can calculate the model weights (i.e., the value representing how "good" each model is, relative to the best model).</span>
<span id="cb80-280"><a href="#cb80-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-283"><a href="#cb80-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-284"><a href="#cb80-284" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the denominator of the weight calculation</span></span>
<span id="cb80-285"><a href="#cb80-285" aria-hidden="true" tabindex="-1"></a>weight_denom <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb80-286"><a href="#cb80-286" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_mod){</span>
<span id="cb80-287"><a href="#cb80-287" aria-hidden="true" tabindex="-1"></a>    weight_denom <span class="ot">=</span> </span>
<span id="cb80-288"><a href="#cb80-288" aria-hidden="true" tabindex="-1"></a>        weight_denom <span class="sc">+</span></span>
<span id="cb80-289"><a href="#cb80-289" aria-hidden="true" tabindex="-1"></a>        <span class="fu">exp</span>( <span class="sc">-</span>Delta_AICc_vec[i] <span class="sc">/</span> <span class="dv">2</span> )</span>
<span id="cb80-290"><a href="#cb80-290" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb80-291"><a href="#cb80-291" aria-hidden="true" tabindex="-1"></a>weight_denom</span>
<span id="cb80-292"><a href="#cb80-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-293"><a href="#cb80-293" aria-hidden="true" tabindex="-1"></a><span class="co"># Now the individual weights:</span></span>
<span id="cb80-294"><a href="#cb80-294" aria-hidden="true" tabindex="-1"></a>weight <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb80-295"><a href="#cb80-295" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_mod){</span>
<span id="cb80-296"><a href="#cb80-296" aria-hidden="true" tabindex="-1"></a>    weight[i] <span class="ot">=</span> </span>
<span id="cb80-297"><a href="#cb80-297" aria-hidden="true" tabindex="-1"></a>        <span class="fu">exp</span>( <span class="sc">-</span>Delta_AICc_vec[i] <span class="sc">/</span> <span class="dv">2</span>) <span class="sc">/</span> weight_denom</span>
<span id="cb80-298"><a href="#cb80-298" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb80-299"><a href="#cb80-299" aria-hidden="true" tabindex="-1"></a>weight</span>
<span id="cb80-300"><a href="#cb80-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-301"><a href="#cb80-301" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum to 1?</span></span>
<span id="cb80-302"><a href="#cb80-302" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(weight)</span>
<span id="cb80-303"><a href="#cb80-303" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-304"><a href="#cb80-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-305"><a href="#cb80-305" aria-hidden="true" tabindex="-1"></a>We can see the "better" models, based on $AIC_c$ have higher weights, and the <span class="in">`weight`</span> vector should add to 1. </span>
<span id="cb80-306"><a href="#cb80-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-307"><a href="#cb80-307" aria-hidden="true" tabindex="-1"></a>Let's calculate the model-averaged slope estimate for input $x_2$. To do this, we'll first need to extract the estimate from each sub-model. This is a little tedious, because we need to know which coefficient refers to $x_2$ in each sub-model object (or if the coefficient is absent and therefore equal to zero).</span>
<span id="cb80-308"><a href="#cb80-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-311"><a href="#cb80-311" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-312"><a href="#cb80-312" aria-hidden="true" tabindex="-1"></a>coef_x2 <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb80-313"><a href="#cb80-313" aria-hidden="true" tabindex="-1"></a>coef_x2[<span class="dv">1</span>] <span class="ot">=</span> <span class="fu">coef</span>(model_list[[<span class="dv">1</span>]])[<span class="dv">3</span>]</span>
<span id="cb80-314"><a href="#cb80-314" aria-hidden="true" tabindex="-1"></a>coef_x2[<span class="dv">2</span>] <span class="ot">=</span> <span class="dv">0</span> <span class="co"># Absent from this sub-model</span></span>
<span id="cb80-315"><a href="#cb80-315" aria-hidden="true" tabindex="-1"></a>coef_x2[<span class="dv">3</span>] <span class="ot">=</span> <span class="fu">coef</span>(model_list[[<span class="dv">3</span>]])[<span class="dv">2</span>]</span>
<span id="cb80-316"><a href="#cb80-316" aria-hidden="true" tabindex="-1"></a>coef_x2[<span class="dv">4</span>] <span class="ot">=</span> <span class="dv">0</span> <span class="co"># Absent from this sub-model</span></span>
<span id="cb80-317"><a href="#cb80-317" aria-hidden="true" tabindex="-1"></a>coef_x2</span>
<span id="cb80-318"><a href="#cb80-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-319"><a href="#cb80-319" aria-hidden="true" tabindex="-1"></a><span class="co"># Averaged, based on model weight:</span></span>
<span id="cb80-320"><a href="#cb80-320" aria-hidden="true" tabindex="-1"></a>avg_coef_x2 <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb80-321"><a href="#cb80-321" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_mod){</span>
<span id="cb80-322"><a href="#cb80-322" aria-hidden="true" tabindex="-1"></a>    avg_coef_x2 <span class="ot">=</span> </span>
<span id="cb80-323"><a href="#cb80-323" aria-hidden="true" tabindex="-1"></a>        avg_coef_x2 <span class="sc">+</span></span>
<span id="cb80-324"><a href="#cb80-324" aria-hidden="true" tabindex="-1"></a>        weight[i] <span class="sc">*</span> coef_x2[i]</span>
<span id="cb80-325"><a href="#cb80-325" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb80-326"><a href="#cb80-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-327"><a href="#cb80-327" aria-hidden="true" tabindex="-1"></a>avg_coef_x2</span>
<span id="cb80-328"><a href="#cb80-328" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-329"><a href="#cb80-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-330"><a href="#cb80-330" aria-hidden="true" tabindex="-1"></a>We can see the model-averaged slope estimate for input $x_2$ is slightly less than the estimate from the full model.</span>
<span id="cb80-331"><a href="#cb80-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-334"><a href="#cb80-334" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-335"><a href="#cb80-335" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(full_mod)</span>
<span id="cb80-336"><a href="#cb80-336" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(full_mod)[<span class="dv">3</span>]</span>
<span id="cb80-337"><a href="#cb80-337" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-338"><a href="#cb80-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-339"><a href="#cb80-339" aria-hidden="true" tabindex="-1"></a>I'll leave calculating the model-averaged standard error of the slopes as an exercise for you as a student. </span>
<span id="cb80-340"><a href="#cb80-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-341"><a href="#cb80-341" aria-hidden="true" tabindex="-1"></a>As I mentioned above, fortunately someone created a package to do this model averaging for us and remove a lot of the tedium. </span>
<span id="cb80-342"><a href="#cb80-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-343"><a href="#cb80-343" aria-hidden="true" tabindex="-1"></a>First, run all sub-models using the <span class="in">`MuMIn::dredge()`</span> function.</span>
<span id="cb80-346"><a href="#cb80-346" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-347"><a href="#cb80-347" aria-hidden="true" tabindex="-1"></a><span class="co"># Required for MuMIn::dredge functionality</span></span>
<span id="cb80-348"><a href="#cb80-348" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">na.action =</span> <span class="st">"na.fail"</span>)</span>
<span id="cb80-349"><a href="#cb80-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-350"><a href="#cb80-350" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit all sub-models:</span></span>
<span id="cb80-351"><a href="#cb80-351" aria-hidden="true" tabindex="-1"></a>dredge_test <span class="ot">=</span> <span class="fu">dredge</span>(full_mod)</span>
<span id="cb80-352"><a href="#cb80-352" aria-hidden="true" tabindex="-1"></a>dredge_test</span>
<span id="cb80-353"><a href="#cb80-353" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-354"><a href="#cb80-354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-355"><a href="#cb80-355" aria-hidden="true" tabindex="-1"></a>See how this output has run all sub-models, calculated the likelihoods, the $AIC_c$, the $\Delta AIC_c$, and the model weights. </span>
<span id="cb80-356"><a href="#cb80-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-357"><a href="#cb80-357" aria-hidden="true" tabindex="-1"></a>Now, we can average all of the models. </span>
<span id="cb80-360"><a href="#cb80-360" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-361"><a href="#cb80-361" aria-hidden="true" tabindex="-1"></a><span class="co"># Average the models:</span></span>
<span id="cb80-362"><a href="#cb80-362" aria-hidden="true" tabindex="-1"></a>test_average <span class="ot">=</span> <span class="fu">model.avg</span>(dredge_test, <span class="at">fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb80-363"><a href="#cb80-363" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(test_average)</span>
<span id="cb80-364"><a href="#cb80-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-365"><a href="#cb80-365" aria-hidden="true" tabindex="-1"></a>This <span class="in">`summary()`</span> statement shows the model-averaged values of slopes of $x_1$ and $x_2$, and the intercept. We care about the "full average". You can see the averaged estimate of the slope for $x_2$ matches our manual calculation. For emphasis:</span>
<span id="cb80-366"><a href="#cb80-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-369"><a href="#cb80-369" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-370"><a href="#cb80-370" aria-hidden="true" tabindex="-1"></a>test_average<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">2</span>];</span>
<span id="cb80-371"><a href="#cb80-371" aria-hidden="true" tabindex="-1"></a>avg_coef_x2</span>
<span id="cb80-372"><a href="#cb80-372" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-373"><a href="#cb80-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-374"><a href="#cb80-374" aria-hidden="true" tabindex="-1"></a><span class="fu">### Back to more complex model</span></span>
<span id="cb80-375"><a href="#cb80-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-376"><a href="#cb80-376" aria-hidden="true" tabindex="-1"></a>Ok, but our full model had four input variables, which means the number of sub-models is $4^2 = 16$. Let's not do that manually, but instead use the <span class="in">`MuMIn::model.avg()`</span> function. </span>
<span id="cb80-377"><a href="#cb80-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-380"><a href="#cb80-380" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-381"><a href="#cb80-381" aria-hidden="true" tabindex="-1"></a><span class="co"># Reminder, m1 was our full model:</span></span>
<span id="cb80-382"><a href="#cb80-382" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1)</span>
<span id="cb80-383"><a href="#cb80-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-384"><a href="#cb80-384" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit all sub-models:</span></span>
<span id="cb80-385"><a href="#cb80-385" aria-hidden="true" tabindex="-1"></a>dredge_m1 <span class="ot">=</span> <span class="fu">dredge</span>(m1)</span>
<span id="cb80-386"><a href="#cb80-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-387"><a href="#cb80-387" aria-hidden="true" tabindex="-1"></a><span class="co"># Average the models:</span></span>
<span id="cb80-388"><a href="#cb80-388" aria-hidden="true" tabindex="-1"></a>m1_average <span class="ot">=</span> <span class="fu">model.avg</span>(dredge_m1, <span class="at">fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb80-389"><a href="#cb80-389" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1_average)</span>
<span id="cb80-390"><a href="#cb80-390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-391"><a href="#cb80-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-392"><a href="#cb80-392" aria-hidden="true" tabindex="-1"></a>Notice how we see the model with inputs $x_2$ and $x_4$ is the best, based on $AIC_c$ (note this is the model labeled as <span class="in">`24`</span> meaning it inclues inputs 2 and 4).</span>
<span id="cb80-393"><a href="#cb80-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-394"><a href="#cb80-394" aria-hidden="true" tabindex="-1"></a>We can also plot the model parameter estimates with their confidence intervals:</span>
<span id="cb80-397"><a href="#cb80-397" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-398"><a href="#cb80-398" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the coefficient estimates (from the averaged model)</span></span>
<span id="cb80-399"><a href="#cb80-399" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m1_average)</span>
<span id="cb80-400"><a href="#cb80-400" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-401"><a href="#cb80-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-402"><a href="#cb80-402" aria-hidden="true" tabindex="-1"></a>Finally, we can use the <span class="in">`predict()`</span> function as we have before to visualize the effect of each input variable on the outcome. Here, we will show the independent, model-averaged effect of $x_2$, when all other input variables are held at their average values. Then, we'll do the same for $x_4$.</span>
<span id="cb80-403"><a href="#cb80-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-406"><a href="#cb80-406" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-407"><a href="#cb80-407" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict from the average model:</span></span>
<span id="cb80-408"><a href="#cb80-408" aria-hidden="true" tabindex="-1"></a><span class="co"># How does y change as a function of x2, while </span></span>
<span id="cb80-409"><a href="#cb80-409" aria-hidden="true" tabindex="-1"></a><span class="co"># other inputs held at their average?</span></span>
<span id="cb80-410"><a href="#cb80-410" aria-hidden="true" tabindex="-1"></a>new_df <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb80-411"><a href="#cb80-411" aria-hidden="true" tabindex="-1"></a>    <span class="at">X1 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X1), <span class="dv">100</span>),</span>
<span id="cb80-412"><a href="#cb80-412" aria-hidden="true" tabindex="-1"></a>    <span class="at">X2 =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">19</span>, <span class="at">length.out =</span> <span class="dv">100</span>),</span>
<span id="cb80-413"><a href="#cb80-413" aria-hidden="true" tabindex="-1"></a>    <span class="at">X3 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X3), <span class="dv">100</span>),</span>
<span id="cb80-414"><a href="#cb80-414" aria-hidden="true" tabindex="-1"></a>    <span class="at">X4 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X4), <span class="dv">100</span>)</span>
<span id="cb80-415"><a href="#cb80-415" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-416"><a href="#cb80-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-417"><a href="#cb80-417" aria-hidden="true" tabindex="-1"></a>pred_m1_avg_x2 <span class="ot">=</span> </span>
<span id="cb80-418"><a href="#cb80-418" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(m1_average,</span>
<span id="cb80-419"><a href="#cb80-419" aria-hidden="true" tabindex="-1"></a>            <span class="at">newdata =</span> new_df,</span>
<span id="cb80-420"><a href="#cb80-420" aria-hidden="true" tabindex="-1"></a>            <span class="at">se.fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb80-421"><a href="#cb80-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-422"><a href="#cb80-422" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> my_df<span class="sc">$</span>X2,</span>
<span id="cb80-423"><a href="#cb80-423" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"input x2"</span>, <span class="at">ylab =</span> <span class="st">"y"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb80-424"><a href="#cb80-424" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x2<span class="sc">$</span>fit <span class="sc">~</span> new_df<span class="sc">$</span>X2)</span>
<span id="cb80-425"><a href="#cb80-425" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x2<span class="sc">$</span>fit<span class="dv">-2</span><span class="sc">*</span>pred_m1_avg_x2<span class="sc">$</span>se.fit <span class="sc">~</span> new_df<span class="sc">$</span>X2, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb80-426"><a href="#cb80-426" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x2<span class="sc">$</span>fit<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>pred_m1_avg_x2<span class="sc">$</span>se.fit <span class="sc">~</span> new_df<span class="sc">$</span>X2, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb80-427"><a href="#cb80-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-428"><a href="#cb80-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-429"><a href="#cb80-429" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict from the average model:</span></span>
<span id="cb80-430"><a href="#cb80-430" aria-hidden="true" tabindex="-1"></a><span class="co"># How does y change as a function of x4, while </span></span>
<span id="cb80-431"><a href="#cb80-431" aria-hidden="true" tabindex="-1"></a><span class="co"># other inputs held at their average?</span></span>
<span id="cb80-432"><a href="#cb80-432" aria-hidden="true" tabindex="-1"></a>new_df <span class="ot">=</span> <span class="fu">data.frame</span>(</span>
<span id="cb80-433"><a href="#cb80-433" aria-hidden="true" tabindex="-1"></a>    <span class="at">X1 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X1), <span class="dv">100</span>),</span>
<span id="cb80-434"><a href="#cb80-434" aria-hidden="true" tabindex="-1"></a>    <span class="at">X2 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X2), <span class="dv">100</span>),</span>
<span id="cb80-435"><a href="#cb80-435" aria-hidden="true" tabindex="-1"></a>    <span class="at">X3 =</span> <span class="fu">rep</span>(<span class="fu">mean</span>(my_df<span class="sc">$</span>X3), <span class="dv">100</span>),</span>
<span id="cb80-436"><a href="#cb80-436" aria-hidden="true" tabindex="-1"></a>    <span class="at">X4 =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">19</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb80-437"><a href="#cb80-437" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb80-438"><a href="#cb80-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-439"><a href="#cb80-439" aria-hidden="true" tabindex="-1"></a>pred_m1_avg_x4 <span class="ot">=</span> </span>
<span id="cb80-440"><a href="#cb80-440" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(m1_average,</span>
<span id="cb80-441"><a href="#cb80-441" aria-hidden="true" tabindex="-1"></a>            <span class="at">newdata =</span> new_df,</span>
<span id="cb80-442"><a href="#cb80-442" aria-hidden="true" tabindex="-1"></a>            <span class="at">se.fit =</span> <span class="cn">TRUE</span>)</span>
<span id="cb80-443"><a href="#cb80-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-444"><a href="#cb80-444" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> my_df<span class="sc">$</span>X4,</span>
<span id="cb80-445"><a href="#cb80-445" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"input x4"</span>, <span class="at">ylab =</span> <span class="st">"y"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb80-446"><a href="#cb80-446" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x4<span class="sc">$</span>fit <span class="sc">~</span> new_df<span class="sc">$</span>X4)</span>
<span id="cb80-447"><a href="#cb80-447" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x4<span class="sc">$</span>fit<span class="dv">-2</span><span class="sc">*</span>pred_m1_avg_x4<span class="sc">$</span>se.fit <span class="sc">~</span> new_df<span class="sc">$</span>X4, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb80-448"><a href="#cb80-448" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(pred_m1_avg_x4<span class="sc">$</span>fit<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>pred_m1_avg_x4<span class="sc">$</span>se.fit <span class="sc">~</span> new_df<span class="sc">$</span>X4, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb80-449"><a href="#cb80-449" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-450"><a href="#cb80-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-451"><a href="#cb80-451" aria-hidden="true" tabindex="-1"></a>Another, perhaps simpler way to vizualize how well a model matches the data is to plot the model predictions of the data versus the observed data. We can even compare this to the non-averaged model.</span>
<span id="cb80-452"><a href="#cb80-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-455"><a href="#cb80-455" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb80-456"><a href="#cb80-456" aria-hidden="true" tabindex="-1"></a>raw_predict_avg <span class="ot">=</span> <span class="fu">predict</span>(m1_average)</span>
<span id="cb80-457"><a href="#cb80-457" aria-hidden="true" tabindex="-1"></a>raw_predict_nonavg <span class="ot">=</span> <span class="fu">predict</span>(m1)</span>
<span id="cb80-458"><a href="#cb80-458" aria-hidden="true" tabindex="-1"></a>raw_predict_bad <span class="ot">=</span> <span class="fu">predict</span>(sub_m2)</span>
<span id="cb80-459"><a href="#cb80-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-460"><a href="#cb80-460" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> raw_predict_avg,</span>
<span id="cb80-461"><a href="#cb80-461" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Model Prediction"</span>, <span class="at">ylab =</span> <span class="st">"Data, y"</span>, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb80-462"><a href="#cb80-462" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> raw_predict_nonavg, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"black"</span>)</span>
<span id="cb80-463"><a href="#cb80-463" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span>(my_df<span class="sc">$</span>y <span class="sc">~</span> raw_predict_bad, <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"orange"</span>)</span>
<span id="cb80-464"><a href="#cb80-464" aria-hidden="true" tabindex="-1"></a><span class="co"># 1-to-1 line</span></span>
<span id="cb80-465"><a href="#cb80-465" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">b =</span> <span class="dv">1</span>)</span>
<span id="cb80-466"><a href="#cb80-466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb80-467"><a href="#cb80-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb80-468"><a href="#cb80-468" aria-hidden="true" tabindex="-1"></a>It is hard to see, and likely not significant in this case, but the red points (model-averaged) tend to be closer to the 1:1 line, compared to the black points, meaning the averaged model makes slightly better predictions of the observed data. What is more clear, is that the "bad" model (which only included covariate $x_1$), does not match the 1:1 line at all; it's more of a shot-gun of points. Therefore, this clearly indicates the model is not predictive of the $y$ data. This is a good visualization of how well your models' within-sample prediction (i.e., how close the model predictions of observed data match the observed data).</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>