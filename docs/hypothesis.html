<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>INF511: Modern Regression I - 5&nbsp; Hypothesis Testing</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./max-lik.html" rel="next">
<link href="./ols.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">INF511: Modern Regression I</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/joseph-mihaljevic/inf511-book" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./software.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Software</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Rintro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prob.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability distributions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ols.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hypothesis.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./max-lik.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">ANOVA</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bayesian.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Bayesian inference</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">Appendices</a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./syllabus.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Syllabus</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#lecture-material" id="toc-lecture-material" class="nav-link active" data-scroll-target="#lecture-material"><span class="toc-section-number">5.1</span>  Lecture material</a></li>
  <li><a href="#sec-data" id="toc-sec-data" class="nav-link" data-scroll-target="#sec-data"><span class="toc-section-number">5.2</span>  Generate the data</a></li>
  <li><a href="#sec-ttest" id="toc-sec-ttest" class="nav-link" data-scroll-target="#sec-ttest"><span class="toc-section-number">5.3</span>  Tests using the <span class="math inline">\(t\)</span>-distribution</a></li>
  <li><a href="#sec-ftest" id="toc-sec-ftest" class="nav-link" data-scroll-target="#sec-ftest"><span class="toc-section-number">5.4</span>  Tests using the <span class="math inline">\(F\)</span>-distribution</a></li>
  <li>
<a href="#sec-r2" id="toc-sec-r2" class="nav-link" data-scroll-target="#sec-r2"><span class="toc-section-number">5.5</span>  Goodness of fit with <span class="math inline">\(R^2\)</span></a>
  <ul class="collapse">
<li><a href="#adjusted-r2" id="toc-adjusted-r2" class="nav-link" data-scroll-target="#adjusted-r2"><span class="toc-section-number">5.5.1</span>  Adjusted <span class="math inline">\(R^2\)</span></a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/joseph-mihaljevic/inf511-book/blob/main/hypothesis.qmd" class="toc-action">View source</a></p><p><a href="https://github.com/joseph-mihaljevic/inf511-book/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-hypothesis" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Hypothesis Testing</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header><section id="lecture-material" class="level2" data-number="5.1"><h2 data-number="5.1" class="anchored" data-anchor-id="lecture-material">
<span class="header-section-number">5.1</span> Lecture material</h2>
<p>Please download and print the lecture materials from <a href="https://bblearn.nau.edu/" target="_blank">Bblearn</a>. After lectures, the recordings will appear in the Bblearn Collaborate Ultra section.</p>
</section><section id="sec-data" class="level2" data-number="5.2"><h2 data-number="5.2" class="anchored" data-anchor-id="sec-data">
<span class="header-section-number">5.2</span> Generate the data</h2>
<p>Here we are going to build on the lecture material by comparing manual calculations of hypothesis tests versus the metrics reported by the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function.</p>
<p>First let’s generate data, in the same way we did for multiple linear regression in (<a href="ols.html"><span>Chapter&nbsp;4</span></a>).</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">n</span> <span class="op">=</span> <span class="fl">80</span></span>
<span><span class="va">n_covariate</span> <span class="op">=</span> <span class="fl">4</span></span>
<span><span class="va">p</span> <span class="op">=</span> <span class="va">n_covariate</span> <span class="op">+</span> <span class="fl">1</span></span>
<span></span>
<span><span class="va">betas</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span><span class="st">"numeric"</span>, length <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">xmat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fl">0</span>, nrow <span class="op">=</span> <span class="va">n</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span></span>
<span><span class="va">sigma</span> <span class="op">=</span> <span class="fl">2.25</span></span>
<span></span>
<span><span class="co"># Column for intercept</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1</span></span>
<span></span>
<span><span class="co"># Generate the covariate data randomly:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">8</span><span class="op">)</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="va">n</span>, min <span class="op">=</span> <span class="fl">0</span>, max <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">rchisq</a></span><span class="op">(</span><span class="va">n</span>, df <span class="op">=</span> <span class="fl">50</span><span class="op">)</span></span>
<span><span class="va">xmat</span><span class="op">[</span>,<span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">rpois</a></span><span class="op">(</span><span class="va">n</span>, lambda <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Set the betas:</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1.0</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">=</span> <span class="fl">0.75</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span> <span class="op">=</span> <span class="op">-</span><span class="fl">1.2</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span> <span class="op">=</span> <span class="fl">0.0</span></span>
<span><span class="va">betas</span><span class="op">[</span><span class="fl">5</span><span class="op">]</span> <span class="op">=</span> <span class="fl">1.8</span></span>
<span></span>
<span><span class="co"># Calculate the observed 'y', adding residual error</span></span>
<span><span class="va">y</span> <span class="op">=</span> <span class="va">xmat</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html">%*%</a></span> <span class="va">betas</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span>, mean <span class="op">=</span> <span class="fl">0</span>, sd <span class="op">=</span> <span class="va">sigma</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw">for</span><span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fl">2</span><span class="op">:</span><span class="va">p</span><span class="op">)</span><span class="op">{</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">xmat</span><span class="op">[</span>,<span class="va">i</span><span class="op">]</span>,</span>
<span>         xlab <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span><span class="op">(</span><span class="st">"covariate "</span>, <span class="va">i</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="hypothesis_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Create a data.frame</span></span>
<span><span class="va">my_df</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span><span class="va">y</span>, <span class="va">xmat</span><span class="op">[</span>,<span class="fl">2</span><span class="op">:</span><span class="fl">5</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">my_df</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          y         X1         X2       X3 X4
1 -4.586806 -1.7268438 13.8180926 61.27634  8
2 27.662332 16.0748747  6.7393185 58.15099 14
3 26.466919 -5.0439349  0.8145552 36.82198 16
4  0.843986  5.5611421 18.1722388 38.24042 10
5 18.891783 18.6915270 16.7070212 51.91376 15
6 12.660545  0.1767361 12.9778881 45.11988 16</code></pre>
</div>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Run the model, report the summary</span></span>
<span><span class="va">m1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">X1</span> <span class="op">+</span> <span class="va">X2</span> <span class="op">+</span> <span class="va">X3</span> <span class="op">+</span> <span class="va">X4</span>, data <span class="op">=</span> <span class="va">my_df</span><span class="op">)</span></span>
<span><span class="va">m1_summary</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span></span>
<span><span class="va">m1_summary</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y ~ 1 + X1 + X2 + X3 + X4, data = my_df)

Residuals:
    Min      1Q  Median      3Q     Max 
-6.4388 -1.4712  0.2816  1.5305  5.0032 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.589838   1.759860   0.903    0.369    
X1           0.737086   0.035629  20.688   &lt;2e-16 ***
X2          -1.295274   0.044252 -29.270   &lt;2e-16 ***
X3          -0.003676   0.028481  -0.129    0.898    
X4           1.826125   0.088971  20.525   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 2.388 on 75 degrees of freedom
Multiple R-squared:  0.9497,    Adjusted R-squared:  0.9471 
F-statistic: 354.3 on 4 and 75 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</section><section id="sec-ttest" class="level2" data-number="5.3"><h2 data-number="5.3" class="anchored" data-anchor-id="sec-ttest">
<span class="header-section-number">5.3</span> Tests using the <span class="math inline">\(t\)</span>-distribution</h2>
<p>We typically use the <span class="math inline">\(t\)</span>-distribution to test the following hypothesis for a specific model coefficient (e.g., an intercept, or a slope): <span class="math display">\[H_0: \beta_i = 0\]</span> <span class="math display">\[H_A: \beta_i \ne 0\]</span> If <span class="math inline">\(\beta_i\)</span> is a slope, then we are specifically testing if input variable <span class="math inline">\(x_i\)</span> has a significant linear relationship with <span class="math inline">\(y\)</span>. Put another way, we are testing whether <span class="math inline">\(x_i\)</span> has a significant linear effect on <span class="math inline">\(y\)</span>.</p>
<p>The <span class="math inline">\(t\)</span>-statistic is calculated as follows: <span class="math display">\[t_i = \frac{\beta_i - \mu}{SE(\beta_i)}, \quad \text{and}\]</span> <span class="math display">\[t_i \sim t(\nu),\]</span></p>
<p>where <span class="math inline">\(t(\nu)\)</span> is a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(\nu=n-p\)</span> degrees of freedom. Then we find <span class="math inline">\(P(t &gt; |t_i|) = 1 - P(t \le |t_i|)\)</span>, which is our <span class="math inline">\(p\)</span>-value for the test.</p>
<p>Let’s manually calculate the <span class="math inline">\(t_i\)</span> and the <span class="math inline">\(P(t &gt; |t_i|)\)</span> for input variables <span class="math inline">\(x_1\)</span>, which has a significant positive effect on <span class="math inline">\(y\)</span>, and for <span class="math inline">\(x_3\)</span>, which has no detectable linear effect on <span class="math inline">\(y\)</span>.</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">## Calculate SE(betas) - We did this in the OLS chapter</span></span>
<span><span class="va">est_sigma</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span></span>
<span><span class="va">xtx_inv</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/solve.html">solve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/crossprod.html">crossprod</a></span><span class="op">(</span><span class="va">xmat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">varcov_betas</span> <span class="op">=</span> <span class="va">xtx_inv</span><span class="op">*</span><span class="va">est_sigma</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="va">se_betas</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">varcov_betas</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Degrees of freedom</span></span>
<span><span class="va">t_df</span> <span class="op">=</span> <span class="va">n</span><span class="op">-</span><span class="va">p</span></span>
<span></span>
<span><span class="co"># extract coef and SE</span></span>
<span><span class="co"># for X1 and X3</span></span>
<span><span class="va">coef_x1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span><span class="va">se_beta_x1</span> <span class="op">=</span> <span class="va">se_betas</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span></span>
<span><span class="va">coef_x3</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m1</span><span class="op">)</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span></span>
<span><span class="va">se_beta_x3</span> <span class="op">=</span> <span class="va">se_betas</span><span class="op">[</span><span class="fl">4</span><span class="op">]</span></span>
<span></span>
<span><span class="co"># Calculate t_i</span></span>
<span><span class="va">t_x1</span> <span class="op">=</span> <span class="op">(</span><span class="va">coef_x1</span> <span class="op">-</span> <span class="fl">0</span><span class="op">)</span><span class="op">/</span><span class="va">se_beta_x1</span></span>
<span><span class="va">t_x3</span> <span class="op">=</span> <span class="op">(</span><span class="va">coef_x3</span> <span class="op">-</span> <span class="fl">0</span><span class="op">)</span><span class="op">/</span><span class="va">se_beta_x3</span></span>
<span></span>
<span></span>
<span><span class="co"># Calculate P(t &gt; |t_i|) = 1 - P(t &lt;= |t_i|)</span></span>
<span><span class="co"># abs() calculates absolute value</span></span>
<span><span class="va">p_x1</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">t_x1</span><span class="op">)</span>, df <span class="op">=</span> <span class="va">t_df</span><span class="op">)</span></span>
<span><span class="va">p_x3</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">t_x3</span><span class="op">)</span>, df <span class="op">=</span> <span class="va">t_df</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Create a table</span></span>
<span><span class="va">t_table</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">t_x1</span>, <span class="va">t_x3</span><span class="op">)</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">rbind</a></span><span class="op">(</span><span class="va">p_x1</span><span class="op">*</span><span class="fl">2</span>, <span class="va">p_x3</span><span class="op">*</span><span class="fl">2</span><span class="op">)</span> <span class="co">#Multiply by 2 for two-tailed test</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">t_table</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"t value"</span>, <span class="st">"Pr(&gt;|t|)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">rownames</a></span><span class="op">(</span><span class="va">t_table</span><span class="op">)</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"X1"</span>, <span class="st">"X3"</span><span class="op">)</span></span>
<span><span class="va">t_table</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      t value  Pr(&gt;|t|)
X1 20.6876284 0.0000000
X3 -0.1290726 0.8976457</code></pre>
</div>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compare to summary of lm()</span></span>
<span><span class="co">## We're extracting just the relevant rows and columns</span></span>
<span><span class="co">## from the summary table </span></span>
<span><span class="va">m1_summary</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">4</span><span class="op">)</span>, <span class="fl">3</span><span class="op">:</span><span class="fl">4</span><span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      t value     Pr(&gt;|t|)
X1 20.6876284 1.008681e-32
X3 -0.1290726 8.976457e-01</code></pre>
</div>
</div>
<p>Let’s plot the <span class="math inline">\(t_i\)</span> on the <span class="math inline">\(t\)</span>-distribution to see if these <span class="math inline">\(p\)</span>-values make sense.</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">tseq</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">21</span>, <span class="fl">21</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">prob_tseq</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">dt</a></span><span class="op">(</span><span class="va">tseq</span>, df <span class="op">=</span> <span class="va">t_df</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">prob_tseq</span> <span class="op">~</span> <span class="va">tseq</span>, type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"t"</span>, ylab <span class="op">=</span> <span class="st">"P(t | df = n-p)"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">t_x1</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>v <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">*</span><span class="va">t_x3</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"orange"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="hypothesis_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can see that the <span class="math inline">\(t\)</span>-statistic for input variable <span class="math inline">\(x_3\)</span> has a very <em>high</em> probability density, suggesting that the chances that the null hypothesis is true (i.e., <span class="math inline">\(\beta_3 = 0\)</span>) is high. In contrast, the <span class="math inline">\(t\)</span>-statistic for input variable <span class="math inline">\(x_1\)</span> has a very <em>low</em> probability density, suggesting that we have enough evidence to reject the null in support of the alternative hypothesis (i.e., <span class="math inline">\(\beta_1 \ne 0\)</span>).</p>
</section><section id="sec-ftest" class="level2" data-number="5.4"><h2 data-number="5.4" class="anchored" data-anchor-id="sec-ftest">
<span class="header-section-number">5.4</span> Tests using the <span class="math inline">\(F\)</span>-distribution</h2>
<p>We can also test the hypothesis: <span class="math display">\[H_0: \beta_1 = \beta_2 = \dots = \beta_{p-1} = 0\]</span> <span class="math display">\[H_A: \beta_i \ne 0, \quad \text{for at least one } i\]</span></p>
<p>This test helps us understand if <em>any</em> of the input variables have a significant linear effect on <span class="math inline">\(y\)</span>, which at this point might not be the most useful test. However, later we will use a version of this test to determine which linear combinations of input variables will lead to the best explanation of <span class="math inline">\(y\)</span>.</p>
<p>For the above hypothesis, we calculate the <span class="math inline">\(F\)</span>-statistic as: <span class="math display">\[F_{stat} = \frac{ \frac{SSE(\text{null}) - SSE(\text{full})}{\text{df}_{\text{null}}-\text{df}_{\text{full}}} }{ \frac{SSE(\text{full})}{\text{df}_{\text{full}}} }, \quad \text{and}\]</span> <span class="math display">\[F_{stat} \sim F(\text{df}_{\text{numerator}}, \text{df}_{\text{denominator}})\]</span></p>
<p>The <span class="math inline">\(SSE(\text{null})\)</span> refers to the sum of squared errors (i.e., residuals) for the null model that takes the form <span class="math inline">\(y_i = \beta_0 + \epsilon_i\)</span>, such that the <span class="math inline">\(E[y_i] = \beta_0 = \bar{y}\)</span>. The <span class="math inline">\(\text{df}_{\text{numerator}}\)</span> is equal to <span class="math inline">\(\text{df}_{\text{null}} - \text{df}_{\text{full}}\)</span>, and the <span class="math inline">\(\text{df}_{\text{denominator}}\)</span> is equal to <span class="math inline">\(\text{df}_{\text{full}}\)</span>.</p>
<p>In this test, we are essentially trying to understand if the full model, which includes all of the input variables in the model, does a better job at explaining the outcome variable compared to a null model that simply explains the data by saying that we should expect to see <span class="math inline">\(y\)</span> values that are most often close to the mean of <span class="math inline">\(y\)</span>, which equals <span class="math inline">\(\bar{y}\)</span>.</p>
<p>Let’s manually calculate the the <span class="math inline">\(F_{stat}\)</span> for the above multiple linear regression model, and then calculate the <span class="math inline">\(p\)</span>-value from the associated <span class="math inline">\(F\)</span>-distribution. First, we need to estimate a null model, which only has an intercept, which again should be estimated as <span class="math inline">\(\bar{y}\)</span>.</p>
<div class="cell">
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">m_null</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span><span class="op">~</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">m_null</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept) 
   10.89976 </code></pre>
</div>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 10.89976</code></pre>
</div>
</div>
<p>Now we can extract all of the information we need from the respective <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> output.</p>
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Extract the residuals (errors)</span></span>
<span><span class="va">resid_null</span> <span class="op">=</span> <span class="va">m_null</span><span class="op">$</span><span class="va">residuals</span></span>
<span><span class="va">resid_full</span> <span class="op">=</span> <span class="va">m1</span><span class="op">$</span><span class="va">residuals</span></span>
<span></span>
<span><span class="co"># Sum of Square Errors (SSE)</span></span>
<span><span class="va">sse_null</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html">crossprod</a></span><span class="op">(</span><span class="va">resid_null</span><span class="op">)</span></span>
<span><span class="va">sse_full</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/crossprod.html">crossprod</a></span><span class="op">(</span><span class="va">resid_full</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># degrees of freedom</span></span>
<span><span class="va">df_null</span> <span class="op">=</span> <span class="va">n</span><span class="op">-</span><span class="fl">1</span></span>
<span><span class="va">df_full</span> <span class="op">=</span> <span class="va">n</span><span class="op">-</span><span class="va">p</span></span>
<span></span>
<span><span class="co"># Calculate F_stat</span></span>
<span><span class="va">f_stat</span> <span class="op">=</span> <span class="op">(</span><span class="op">(</span><span class="va">sse_null</span> <span class="op">-</span> <span class="va">sse_full</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="va">df_null</span> <span class="op">-</span> <span class="va">df_full</span><span class="op">)</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="va">sse_full</span><span class="op">/</span><span class="va">df_full</span><span class="op">)</span></span>
<span><span class="va">f_stat</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         [,1]
[1,] 354.3369</code></pre>
</div>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Degrees of freedom for the F distribution:</span></span>
<span><span class="va">df_numerator</span> <span class="op">=</span> <span class="va">df_null</span> <span class="op">-</span> <span class="va">df_full</span></span>
<span><span class="va">df_denominator</span> <span class="op">=</span> <span class="va">df_full</span></span>
<span><span class="va">df_numerator</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4</code></pre>
</div>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">df_denominator</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 75</code></pre>
</div>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compare this to the lm() output:</span></span>
<span><span class="va">m1_summary</span><span class="op">$</span><span class="va">fstatistic</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   value    numdf    dendf 
354.3369   4.0000  75.0000 </code></pre>
</div>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Visualize the associated F distribution</span></span>
<span><span class="va">fseq</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span>, by <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span></span>
<span><span class="va">p_fseq</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">df</a></span><span class="op">(</span><span class="va">fseq</span>,</span>
<span>            df1 <span class="op">=</span> <span class="va">df_numerator</span>,</span>
<span>            df2 <span class="op">=</span> <span class="va">df_denominator</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">p_fseq</span> <span class="op">~</span> <span class="va">fseq</span>, type <span class="op">=</span> <span class="st">"l"</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"F"</span>, ylab <span class="op">=</span> <span class="st">"P(F | df1, df2)"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="hypothesis_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Notice how the <span class="math inline">\(F_{stat} &gt; 350\)</span>, which is far outside the range of our figure above, meaning that it has a very low probability density. We can formally calculate the <span class="math inline">\(p\)</span>-value below:</p>
<div class="cell">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co">#P(F &gt; f_stat) = 1 - P(F &lt;= f_stat)</span></span>
<span><span class="va">p_f_m1</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">pf</a></span><span class="op">(</span><span class="va">f_stat</span>,</span>
<span>                df1 <span class="op">=</span> <span class="va">df_numerator</span>,</span>
<span>                df2 <span class="op">=</span> <span class="va">df_denominator</span><span class="op">)</span></span>
<span><span class="va">p_f_m1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     [,1]
[1,]    0</code></pre>
</div>
</div>
<p>Although this <span class="math inline">\(p\)</span>-value is zero, what this really means is that the <span class="math inline">\(p\)</span>-value is so low, that it exceeds the significant digits that are allowed in (computer) memory, which is why the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> output reports the <code>p-value: &lt; 2.2e-16</code>.</p>
</section><section id="sec-r2" class="level2" data-number="5.5"><h2 data-number="5.5" class="anchored" data-anchor-id="sec-r2">
<span class="header-section-number">5.5</span> Goodness of fit with <span class="math inline">\(R^2\)</span>
</h2>
<p>The <code>summary</code> of the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> output also reports the <code>Multiple R-squared</code>, which is also referred to as the coefficient of determination, or simply <span class="math inline">\(R^2\)</span> of the model. <span class="math inline">\(R^2\)</span> provides a metric of “goodness of fit” for the model. This value roughly equates to the fraction of the variability in outcome variable <span class="math inline">\(y\)</span> that is explained by the linear combination of input variables that are included in the model.</p>
<p><span class="math display">\[ R^2 = 1 - \frac{SSE(\text{full})}{SSE(\text{null})}\]</span> Thus, the <span class="math inline">\(R^2\)</span> is approximately calculating the reduction in residual error that occurs when you add meaningful input variables, compared to the null model that only has an intercept (i.e., predicting <span class="math inline">\(y\)</span> based on its mean value).</p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">r2</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="va">sse_full</span><span class="op">/</span><span class="va">sse_null</span></span>
<span><span class="va">r2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]
[1,] 0.9497436</code></pre>
</div>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compared to the lm() output</span></span>
<span><span class="va">m1_summary</span><span class="op">$</span><span class="va">r.squared</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9497436</code></pre>
</div>
</div>
<p>What we see here is that the inclusion of the four input variables in the model explains approximately 95% of the variability in outcome variable <span class="math inline">\(y\)</span>. This makes sense, because we simulated the data <span class="math inline">\(y\)</span> from a known set of input variables with a known set of coefficients.</p>
<p>What happens to this <span class="math inline">\(R^2\)</span> value if we remove a meaningful input variable from the model? In other words, what if we didn’t actually know all of the correct input variables to measure in real life that explain <span class="math inline">\(y\)</span>, and we didn’t measure an important one?</p>
<div class="cell">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Run a model that does not include input variable X2</span></span>
<span><span class="va">m2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="fl">1</span> <span class="op">+</span> <span class="va">X1</span> <span class="op">+</span> <span class="va">X3</span> <span class="op">+</span> <span class="va">X4</span>, data <span class="op">=</span> <span class="va">my_df</span><span class="op">)</span></span>
<span><span class="va">m2_summary</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">m2</span><span class="op">)</span></span>
<span><span class="co"># Extract the R^2</span></span>
<span><span class="va">m2_summary</span><span class="op">$</span><span class="va">r.squared</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.3756416</code></pre>
</div>
</div>
<p>The <span class="math inline">\(R^2\)</span> has reduced from 95% to 38%, meaning that without the inclusion of input variable <span class="math inline">\(x_2\)</span> in our model, we reduce our ability to explain (i.e., predict) the outcome <span class="math inline">\(y\)</span> by approximately 60%.</p>
<section id="adjusted-r2" class="level3" data-number="5.5.1"><h3 data-number="5.5.1" class="anchored" data-anchor-id="adjusted-r2">
<span class="header-section-number">5.5.1</span> Adjusted <span class="math inline">\(R^2\)</span>
</h3>
<p>Another measure in the <code>summary</code> of <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> output is an “adjusted” value of <span class="math inline">\(R^2\)</span>, which penalizes the value of <span class="math inline">\(R^2\)</span> for models that have a lot of parameters (<span class="math inline">\(p\)</span>) compared to the number of data points (<span class="math inline">\(n\)</span>).</p>
<p><span class="math display">\[\text{Adjusted } R^2 = 1 - \frac{n-1}{n-p} + \frac{n-1}{n-p} R^2\]</span></p>
<div class="cell">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="va">adjusted_r2</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">-</span> <span class="op">(</span><span class="va">n</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="va">n</span><span class="op">-</span><span class="va">p</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="va">n</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="op">(</span><span class="va">n</span><span class="op">-</span><span class="va">p</span><span class="op">)</span><span class="op">*</span><span class="va">r2</span></span>
<span><span class="va">adjusted_r2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          [,1]
[1,] 0.9470633</code></pre>
</div>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Compared to lm() output</span></span>
<span><span class="va">m1_summary</span><span class="op">$</span><span class="va">adj.r.squared</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9470633</code></pre>
</div>
</div>
<p>If you have more parameters (i.e., more input variables) relative to the number of observed data points, then the Adjusted <span class="math inline">\(R^2\)</span> will be less than <span class="math inline">\(R^2\)</span>. In the model above, we have many data points (<span class="math inline">\(n=80\)</span>) relative to the number of input variables (<span class="math inline">\(p-1 = 4\)</span>), so there is only a small difference in the two metrics.</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Congratulations!
</div>
</div>
<div class="callout-body-container callout-body">
<p>Look at the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> of the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> output. You should now be able to explain (and manually calculate) every value that is printed in that output. You now have a deep understanding of the ordinary least squares (OLS) regression analysis and associated methods of hypothesis-testing.</p>
</div>
</div>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./ols.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ordinary Least Squares</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./max-lik.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Maximum Likelihood</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb36" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Hypothesis Testing {#sec-hypothesis}</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="fu">## Lecture material</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>Please download and print the lecture materials from <span class="co">[</span><span class="ot">Bblearn</span><span class="co">](https://bblearn.nau.edu/)</span>{target="_blank"}. After lectures, the recordings will appear in the Bblearn Collaborate Ultra section.</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## Generate the data {#sec-data}</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>Here we are going to build on the lecture material by comparing manual calculations of hypothesis tests versus the metrics reported by the <span class="in">`lm()`</span> function. </span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>First let's generate data, in the same way we did for multiple linear regression in (@sec-ols).</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">80</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>n_covariate <span class="ot">=</span> <span class="dv">4</span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>p <span class="ot">=</span> n_covariate <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">=</span> <span class="fu">vector</span>(<span class="st">"numeric"</span>, <span class="at">length =</span> p)</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>xmat <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>, <span class="at">nrow =</span> n, <span class="at">ncol =</span> p)</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fl">2.25</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Column for intercept</span></span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">1</span>] <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the covariate data randomly:</span></span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5</span>)</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">2</span>] <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">8</span>)</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">3</span>] <span class="ot">=</span> <span class="fu">runif</span>(n, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">20</span>)</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">4</span>] <span class="ot">=</span> <span class="fu">rchisq</span>(n, <span class="at">df =</span> <span class="dv">50</span>)</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>xmat[,<span class="dv">5</span>] <span class="ot">=</span> <span class="fu">rpois</span>(n, <span class="at">lambda =</span> <span class="dv">10</span>)</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Set the betas:</span></span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">1</span>] <span class="ot">=</span> <span class="fl">1.0</span></span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">2</span>] <span class="ot">=</span> <span class="fl">0.75</span></span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">3</span>] <span class="ot">=</span> <span class="sc">-</span><span class="fl">1.2</span></span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">4</span>] <span class="ot">=</span> <span class="fl">0.0</span></span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>betas[<span class="dv">5</span>] <span class="ot">=</span> <span class="fl">1.8</span></span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the observed 'y', adding residual error</span></span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> xmat <span class="sc">%*%</span> betas <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>p){</span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(y <span class="sc">~</span> xmat[,i],</span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="fu">paste</span>(<span class="st">"covariate "</span>, i<span class="dv">-1</span>))</span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a data.frame</span></span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>my_df <span class="ot">=</span> <span class="fu">data.frame</span>(y, xmat[,<span class="dv">2</span><span class="sc">:</span><span class="dv">5</span>])</span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(my_df)</span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the model, report the summary</span></span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3 <span class="sc">+</span> X4, <span class="at">data =</span> my_df)</span>
<span id="cb36-56"><a href="#cb36-56" aria-hidden="true" tabindex="-1"></a>m1_summary <span class="ot">=</span> <span class="fu">summary</span>(m1)</span>
<span id="cb36-57"><a href="#cb36-57" aria-hidden="true" tabindex="-1"></a>m1_summary</span>
<span id="cb36-58"><a href="#cb36-58" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-59"><a href="#cb36-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-60"><a href="#cb36-60" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tests using the $t$-distribution {#sec-ttest}</span></span>
<span id="cb36-61"><a href="#cb36-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-62"><a href="#cb36-62" aria-hidden="true" tabindex="-1"></a>We typically use the $t$-distribution to test the following hypothesis for a specific model coefficient (e.g., an intercept, or a slope):</span>
<span id="cb36-63"><a href="#cb36-63" aria-hidden="true" tabindex="-1"></a>$$H_0: \beta_i = 0$$</span>
<span id="cb36-64"><a href="#cb36-64" aria-hidden="true" tabindex="-1"></a>$$H_A: \beta_i \ne 0$$</span>
<span id="cb36-65"><a href="#cb36-65" aria-hidden="true" tabindex="-1"></a>If $\beta_i$ is a slope, then we are specifically testing if input variable $x_i$ has a significant linear relationship with $y$. Put another way, we are testing whether $x_i$ has a significant linear effect on $y$. </span>
<span id="cb36-66"><a href="#cb36-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-67"><a href="#cb36-67" aria-hidden="true" tabindex="-1"></a>The $t$-statistic is calculated as follows:</span>
<span id="cb36-68"><a href="#cb36-68" aria-hidden="true" tabindex="-1"></a>$$t_i = \frac{\beta_i - \mu}{SE(\beta_i)}, \quad \text{and}$$ </span>
<span id="cb36-69"><a href="#cb36-69" aria-hidden="true" tabindex="-1"></a>$$t_i \sim t(\nu),$$ </span>
<span id="cb36-70"><a href="#cb36-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-71"><a href="#cb36-71" aria-hidden="true" tabindex="-1"></a>where $t(\nu)$ is a $t$-distribution with $\nu=n-p$ degrees of freedom. Then we find $P(t &gt; |t_i|) = 1 - P(t \le |t_i|)$, which is our $p$-value for the test. </span>
<span id="cb36-72"><a href="#cb36-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-73"><a href="#cb36-73" aria-hidden="true" tabindex="-1"></a>Let's manually calculate the $t_i$ and the $P(t &gt; |t_i|)$ for input variables $x_1$, which has a significant positive effect on $y$, and for $x_3$, which has no detectable linear effect on $y$. </span>
<span id="cb36-74"><a href="#cb36-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-77"><a href="#cb36-77" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-78"><a href="#cb36-78" aria-hidden="true" tabindex="-1"></a><span class="do">## Calculate SE(betas) - We did this in the OLS chapter</span></span>
<span id="cb36-79"><a href="#cb36-79" aria-hidden="true" tabindex="-1"></a>est_sigma <span class="ot">=</span> <span class="fu">summary</span>(m1)<span class="sc">$</span>sigma</span>
<span id="cb36-80"><a href="#cb36-80" aria-hidden="true" tabindex="-1"></a>xtx_inv <span class="ot">=</span> <span class="fu">solve</span>(<span class="fu">crossprod</span>(xmat))</span>
<span id="cb36-81"><a href="#cb36-81" aria-hidden="true" tabindex="-1"></a>varcov_betas <span class="ot">=</span> xtx_inv<span class="sc">*</span>est_sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb36-82"><a href="#cb36-82" aria-hidden="true" tabindex="-1"></a>se_betas <span class="ot">=</span> <span class="fu">sqrt</span>(<span class="fu">diag</span>(varcov_betas))</span>
<span id="cb36-83"><a href="#cb36-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-84"><a href="#cb36-84" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of freedom</span></span>
<span id="cb36-85"><a href="#cb36-85" aria-hidden="true" tabindex="-1"></a>t_df <span class="ot">=</span> n<span class="sc">-</span>p</span>
<span id="cb36-86"><a href="#cb36-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-87"><a href="#cb36-87" aria-hidden="true" tabindex="-1"></a><span class="co"># extract coef and SE</span></span>
<span id="cb36-88"><a href="#cb36-88" aria-hidden="true" tabindex="-1"></a><span class="co"># for X1 and X3</span></span>
<span id="cb36-89"><a href="#cb36-89" aria-hidden="true" tabindex="-1"></a>coef_x1 <span class="ot">=</span> <span class="fu">coef</span>(m1)[<span class="dv">2</span>]</span>
<span id="cb36-90"><a href="#cb36-90" aria-hidden="true" tabindex="-1"></a>se_beta_x1 <span class="ot">=</span> se_betas[<span class="dv">2</span>]</span>
<span id="cb36-91"><a href="#cb36-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-92"><a href="#cb36-92" aria-hidden="true" tabindex="-1"></a>coef_x3 <span class="ot">=</span> <span class="fu">coef</span>(m1)[<span class="dv">4</span>]</span>
<span id="cb36-93"><a href="#cb36-93" aria-hidden="true" tabindex="-1"></a>se_beta_x3 <span class="ot">=</span> se_betas[<span class="dv">4</span>]</span>
<span id="cb36-94"><a href="#cb36-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-95"><a href="#cb36-95" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate t_i</span></span>
<span id="cb36-96"><a href="#cb36-96" aria-hidden="true" tabindex="-1"></a>t_x1 <span class="ot">=</span> (coef_x1 <span class="sc">-</span> <span class="dv">0</span>)<span class="sc">/</span>se_beta_x1</span>
<span id="cb36-97"><a href="#cb36-97" aria-hidden="true" tabindex="-1"></a>t_x3 <span class="ot">=</span> (coef_x3 <span class="sc">-</span> <span class="dv">0</span>)<span class="sc">/</span>se_beta_x3</span>
<span id="cb36-98"><a href="#cb36-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-99"><a href="#cb36-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-100"><a href="#cb36-100" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate P(t &gt; |t_i|) = 1 - P(t &lt;= |t_i|)</span></span>
<span id="cb36-101"><a href="#cb36-101" aria-hidden="true" tabindex="-1"></a><span class="co"># abs() calculates absolute value</span></span>
<span id="cb36-102"><a href="#cb36-102" aria-hidden="true" tabindex="-1"></a>p_x1 <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(<span class="fu">abs</span>(t_x1), <span class="at">df =</span> t_df)</span>
<span id="cb36-103"><a href="#cb36-103" aria-hidden="true" tabindex="-1"></a>p_x3 <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pt</span>(<span class="fu">abs</span>(t_x3), <span class="at">df =</span> t_df)</span>
<span id="cb36-104"><a href="#cb36-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-105"><a href="#cb36-105" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a table</span></span>
<span id="cb36-106"><a href="#cb36-106" aria-hidden="true" tabindex="-1"></a>t_table <span class="ot">=</span> <span class="fu">cbind</span>(</span>
<span id="cb36-107"><a href="#cb36-107" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(t_x1, t_x3),</span>
<span id="cb36-108"><a href="#cb36-108" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(p_x1<span class="sc">*</span><span class="dv">2</span>, p_x3<span class="sc">*</span><span class="dv">2</span>) <span class="co">#Multiply by 2 for two-tailed test</span></span>
<span id="cb36-109"><a href="#cb36-109" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb36-110"><a href="#cb36-110" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(t_table) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"t value"</span>, <span class="st">"Pr(&gt;|t|)"</span>)</span>
<span id="cb36-111"><a href="#cb36-111" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(t_table) <span class="ot">=</span> <span class="fu">c</span>(<span class="st">"X1"</span>, <span class="st">"X3"</span>)</span>
<span id="cb36-112"><a href="#cb36-112" aria-hidden="true" tabindex="-1"></a>t_table</span>
<span id="cb36-113"><a href="#cb36-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-114"><a href="#cb36-114" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to summary of lm()</span></span>
<span id="cb36-115"><a href="#cb36-115" aria-hidden="true" tabindex="-1"></a><span class="do">## We're extracting just the relevant rows and columns</span></span>
<span id="cb36-116"><a href="#cb36-116" aria-hidden="true" tabindex="-1"></a><span class="do">## from the summary table </span></span>
<span id="cb36-117"><a href="#cb36-117" aria-hidden="true" tabindex="-1"></a>m1_summary<span class="sc">$</span>coefficients[<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>), <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>]</span>
<span id="cb36-118"><a href="#cb36-118" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-119"><a href="#cb36-119" aria-hidden="true" tabindex="-1"></a>Let's plot the $t_i$ on the $t$-distribution to see if these $p$-values make sense.</span>
<span id="cb36-122"><a href="#cb36-122" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-123"><a href="#cb36-123" aria-hidden="true" tabindex="-1"></a>tseq <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">21</span>, <span class="dv">21</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb36-124"><a href="#cb36-124" aria-hidden="true" tabindex="-1"></a>prob_tseq <span class="ot">=</span> <span class="fu">dt</span>(tseq, <span class="at">df =</span> t_df)</span>
<span id="cb36-125"><a href="#cb36-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-126"><a href="#cb36-126" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prob_tseq <span class="sc">~</span> tseq, <span class="at">type =</span> <span class="st">"l"</span>,</span>
<span id="cb36-127"><a href="#cb36-127" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"t"</span>, <span class="at">ylab =</span> <span class="st">"P(t | df = n-p)"</span>)</span>
<span id="cb36-128"><a href="#cb36-128" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>t_x1, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"blue"</span>)</span>
<span id="cb36-129"><a href="#cb36-129" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)<span class="sc">*</span>t_x3, <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"orange"</span>)</span>
<span id="cb36-130"><a href="#cb36-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-131"><a href="#cb36-131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-132"><a href="#cb36-132" aria-hidden="true" tabindex="-1"></a>We can see that the $t$-statistic for input variable $x_3$ has a very *high* probability density, suggesting that the chances that the null hypothesis is true (i.e., $\beta_3 = 0$) is high. In contrast, the $t$-statistic for input variable $x_1$ has a very *low* probability density, suggesting that we have enough evidence to reject the null in support of the alternative hypothesis (i.e., $\beta_1 \ne 0$).</span>
<span id="cb36-133"><a href="#cb36-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-134"><a href="#cb36-134" aria-hidden="true" tabindex="-1"></a><span class="fu">## Tests using the $F$-distribution {#sec-ftest}</span></span>
<span id="cb36-135"><a href="#cb36-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-136"><a href="#cb36-136" aria-hidden="true" tabindex="-1"></a>We can also test the hypothesis:</span>
<span id="cb36-137"><a href="#cb36-137" aria-hidden="true" tabindex="-1"></a>$$H_0: \beta_1 = \beta_2 = \dots = \beta_{p-1} = 0$$</span>
<span id="cb36-138"><a href="#cb36-138" aria-hidden="true" tabindex="-1"></a>$$H_A: \beta_i \ne 0, \quad \text{for at least one } i$$</span>
<span id="cb36-139"><a href="#cb36-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-140"><a href="#cb36-140" aria-hidden="true" tabindex="-1"></a>This test helps us understand if *any* of the input variables have a significant linear effect on $y$, which at this point might not be the most useful test. However, later we will use a version of this test to determine which linear combinations of input variables will lead to the best explanation of $y$.</span>
<span id="cb36-141"><a href="#cb36-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-142"><a href="#cb36-142" aria-hidden="true" tabindex="-1"></a>For the above hypothesis, we calculate the $F$-statistic as:</span>
<span id="cb36-143"><a href="#cb36-143" aria-hidden="true" tabindex="-1"></a>$$F_{stat} = \frac{ \frac{SSE(\text{null}) - SSE(\text{full})}{\text{df}_{\text{null}}-\text{df}_{\text{full}}} }{ \frac{SSE(\text{full})}{\text{df}_{\text{full}}} }, \quad \text{and}$$</span>
<span id="cb36-144"><a href="#cb36-144" aria-hidden="true" tabindex="-1"></a>$$F_{stat} \sim F(\text{df}_{\text{numerator}}, \text{df}_{\text{denominator}})$$</span>
<span id="cb36-145"><a href="#cb36-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-146"><a href="#cb36-146" aria-hidden="true" tabindex="-1"></a>The $SSE(\text{null})$ refers to the sum of squared errors (i.e., residuals) for the null model that takes the form $y_i = \beta_0 + \epsilon_i$, such that the $E<span class="co">[</span><span class="ot">y_i</span><span class="co">]</span> = \beta_0 = \bar{y}$. </span>
<span id="cb36-147"><a href="#cb36-147" aria-hidden="true" tabindex="-1"></a>The $\text{df}_{\text{numerator}}$ is equal to $\text{df}_{\text{null}} - \text{df}_{\text{full}}$, and the $\text{df}_{\text{denominator}}$ is equal to  $\text{df}_{\text{full}}$. </span>
<span id="cb36-148"><a href="#cb36-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-149"><a href="#cb36-149" aria-hidden="true" tabindex="-1"></a>In this test, we are essentially trying to understand if the full model, which includes all of the input variables in the model, does a better job at explaining the outcome variable compared to a null model that simply explains the data by saying that we should expect to see $y$ values that are most often close to the mean of $y$, which equals $\bar{y}$. </span>
<span id="cb36-150"><a href="#cb36-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-151"><a href="#cb36-151" aria-hidden="true" tabindex="-1"></a>Let's manually calculate the the $F_{stat}$ for the above multiple linear regression model, and then calculate the $p$-value from the associated $F$-distribution. First, we need to estimate a null model, which only has an intercept, which again should be estimated as $\bar{y}$.</span>
<span id="cb36-152"><a href="#cb36-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-155"><a href="#cb36-155" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-156"><a href="#cb36-156" aria-hidden="true" tabindex="-1"></a>m_null <span class="ot">=</span> <span class="fu">lm</span>(y<span class="sc">~</span><span class="dv">1</span>)</span>
<span id="cb36-157"><a href="#cb36-157" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(m_null)</span>
<span id="cb36-158"><a href="#cb36-158" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y)</span>
<span id="cb36-159"><a href="#cb36-159" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-160"><a href="#cb36-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-161"><a href="#cb36-161" aria-hidden="true" tabindex="-1"></a>Now we can extract all of the information we need from the respective <span class="in">`lm()`</span> output.</span>
<span id="cb36-164"><a href="#cb36-164" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-165"><a href="#cb36-165" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the residuals (errors)</span></span>
<span id="cb36-166"><a href="#cb36-166" aria-hidden="true" tabindex="-1"></a>resid_null <span class="ot">=</span> m_null<span class="sc">$</span>residuals</span>
<span id="cb36-167"><a href="#cb36-167" aria-hidden="true" tabindex="-1"></a>resid_full <span class="ot">=</span> m1<span class="sc">$</span>residuals</span>
<span id="cb36-168"><a href="#cb36-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-169"><a href="#cb36-169" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of Square Errors (SSE)</span></span>
<span id="cb36-170"><a href="#cb36-170" aria-hidden="true" tabindex="-1"></a>sse_null <span class="ot">=</span> <span class="fu">crossprod</span>(resid_null)</span>
<span id="cb36-171"><a href="#cb36-171" aria-hidden="true" tabindex="-1"></a>sse_full <span class="ot">=</span> <span class="fu">crossprod</span>(resid_full)</span>
<span id="cb36-172"><a href="#cb36-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-173"><a href="#cb36-173" aria-hidden="true" tabindex="-1"></a><span class="co"># degrees of freedom</span></span>
<span id="cb36-174"><a href="#cb36-174" aria-hidden="true" tabindex="-1"></a>df_null <span class="ot">=</span> n<span class="dv">-1</span></span>
<span id="cb36-175"><a href="#cb36-175" aria-hidden="true" tabindex="-1"></a>df_full <span class="ot">=</span> n<span class="sc">-</span>p</span>
<span id="cb36-176"><a href="#cb36-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-177"><a href="#cb36-177" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate F_stat</span></span>
<span id="cb36-178"><a href="#cb36-178" aria-hidden="true" tabindex="-1"></a>f_stat <span class="ot">=</span> ((sse_null <span class="sc">-</span> sse_full)<span class="sc">/</span>(df_null <span class="sc">-</span> df_full)) <span class="sc">/</span> (sse_full<span class="sc">/</span>df_full)</span>
<span id="cb36-179"><a href="#cb36-179" aria-hidden="true" tabindex="-1"></a>f_stat</span>
<span id="cb36-180"><a href="#cb36-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-181"><a href="#cb36-181" aria-hidden="true" tabindex="-1"></a><span class="co"># Degrees of freedom for the F distribution:</span></span>
<span id="cb36-182"><a href="#cb36-182" aria-hidden="true" tabindex="-1"></a>df_numerator <span class="ot">=</span> df_null <span class="sc">-</span> df_full</span>
<span id="cb36-183"><a href="#cb36-183" aria-hidden="true" tabindex="-1"></a>df_denominator <span class="ot">=</span> df_full</span>
<span id="cb36-184"><a href="#cb36-184" aria-hidden="true" tabindex="-1"></a>df_numerator</span>
<span id="cb36-185"><a href="#cb36-185" aria-hidden="true" tabindex="-1"></a>df_denominator</span>
<span id="cb36-186"><a href="#cb36-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-187"><a href="#cb36-187" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare this to the lm() output:</span></span>
<span id="cb36-188"><a href="#cb36-188" aria-hidden="true" tabindex="-1"></a>m1_summary<span class="sc">$</span>fstatistic</span>
<span id="cb36-189"><a href="#cb36-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-190"><a href="#cb36-190" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the associated F distribution</span></span>
<span id="cb36-191"><a href="#cb36-191" aria-hidden="true" tabindex="-1"></a>fseq <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb36-192"><a href="#cb36-192" aria-hidden="true" tabindex="-1"></a>p_fseq <span class="ot">=</span> <span class="fu">df</span>(fseq,</span>
<span id="cb36-193"><a href="#cb36-193" aria-hidden="true" tabindex="-1"></a>            <span class="at">df1 =</span> df_numerator,</span>
<span id="cb36-194"><a href="#cb36-194" aria-hidden="true" tabindex="-1"></a>            <span class="at">df2 =</span> df_denominator)</span>
<span id="cb36-195"><a href="#cb36-195" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(p_fseq <span class="sc">~</span> fseq, <span class="at">type =</span> <span class="st">"l"</span>,</span>
<span id="cb36-196"><a href="#cb36-196" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"F"</span>, <span class="at">ylab =</span> <span class="st">"P(F | df1, df2)"</span>)</span>
<span id="cb36-197"><a href="#cb36-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-198"><a href="#cb36-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-199"><a href="#cb36-199" aria-hidden="true" tabindex="-1"></a>Notice how the $F_{stat} &gt; 350$, which is far outside the range of our figure above, meaning that it has a very low probability density. We can formally calculate the $p$-value below:</span>
<span id="cb36-200"><a href="#cb36-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-203"><a href="#cb36-203" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-204"><a href="#cb36-204" aria-hidden="true" tabindex="-1"></a><span class="co">#P(F &gt; f_stat) = 1 - P(F &lt;= f_stat)</span></span>
<span id="cb36-205"><a href="#cb36-205" aria-hidden="true" tabindex="-1"></a>p_f_m1 <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">pf</span>(f_stat,</span>
<span id="cb36-206"><a href="#cb36-206" aria-hidden="true" tabindex="-1"></a>                <span class="at">df1 =</span> df_numerator,</span>
<span id="cb36-207"><a href="#cb36-207" aria-hidden="true" tabindex="-1"></a>                <span class="at">df2 =</span> df_denominator)</span>
<span id="cb36-208"><a href="#cb36-208" aria-hidden="true" tabindex="-1"></a>p_f_m1</span>
<span id="cb36-209"><a href="#cb36-209" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-210"><a href="#cb36-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-211"><a href="#cb36-211" aria-hidden="true" tabindex="-1"></a>Although this $p$-value is zero, what this really means is that the $p$-value is so low, that it exceeds the significant digits that are allowed in (computer) memory, which is why the <span class="in">`lm()`</span> output reports the <span class="in">`p-value: &lt; 2.2e-16`</span>. </span>
<span id="cb36-212"><a href="#cb36-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-213"><a href="#cb36-213" aria-hidden="true" tabindex="-1"></a><span class="fu">## Goodness of fit with $R^2$ {#sec-r2}</span></span>
<span id="cb36-214"><a href="#cb36-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-215"><a href="#cb36-215" aria-hidden="true" tabindex="-1"></a>The <span class="in">`summary`</span> of the <span class="in">`lm()`</span> output also reports the <span class="in">`Multiple R-squared`</span>, which is also referred to as the coefficient of determination, or simply $R^2$ of the model. $R^2$ provides a metric of "goodness of fit" for the model. This value roughly equates to the fraction of the variability in outcome variable $y$ that is explained by the linear combination of input variables that are included in the model. </span>
<span id="cb36-216"><a href="#cb36-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-217"><a href="#cb36-217" aria-hidden="true" tabindex="-1"></a>$$ R^2 = 1 - \frac{SSE(\text{full})}{SSE(\text{null})}$$</span>
<span id="cb36-218"><a href="#cb36-218" aria-hidden="true" tabindex="-1"></a>Thus, the $R^2$ is approximately calculating the reduction in residual error that occurs when you add meaningful input variables, compared to the null model that only has an intercept (i.e., predicting $y$ based on its mean value). </span>
<span id="cb36-219"><a href="#cb36-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-222"><a href="#cb36-222" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-223"><a href="#cb36-223" aria-hidden="true" tabindex="-1"></a>r2 <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> sse_full<span class="sc">/</span>sse_null</span>
<span id="cb36-224"><a href="#cb36-224" aria-hidden="true" tabindex="-1"></a>r2</span>
<span id="cb36-225"><a href="#cb36-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-226"><a href="#cb36-226" aria-hidden="true" tabindex="-1"></a><span class="co"># Compared to the lm() output</span></span>
<span id="cb36-227"><a href="#cb36-227" aria-hidden="true" tabindex="-1"></a>m1_summary<span class="sc">$</span>r.squared</span>
<span id="cb36-228"><a href="#cb36-228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-229"><a href="#cb36-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-230"><a href="#cb36-230" aria-hidden="true" tabindex="-1"></a>What we see here is that the inclusion of the four input variables in the model explains approximately 95% of the variability in outcome variable $y$. This makes sense, because we simulated the data $y$ from a known set of input variables with a known set of coefficients.  </span>
<span id="cb36-231"><a href="#cb36-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-232"><a href="#cb36-232" aria-hidden="true" tabindex="-1"></a>What happens to this $R^2$ value if we remove a meaningful input variable from the model? In other words, what if we didn't actually know all of the correct input variables to measure in real life that explain $y$, and we didn't measure an important one?</span>
<span id="cb36-233"><a href="#cb36-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-236"><a href="#cb36-236" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-237"><a href="#cb36-237" aria-hidden="true" tabindex="-1"></a><span class="co"># Run a model that does not include input variable X2</span></span>
<span id="cb36-238"><a href="#cb36-238" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">=</span> <span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span> <span class="sc">+</span> X1 <span class="sc">+</span> X3 <span class="sc">+</span> X4, <span class="at">data =</span> my_df)</span>
<span id="cb36-239"><a href="#cb36-239" aria-hidden="true" tabindex="-1"></a>m2_summary <span class="ot">=</span> <span class="fu">summary</span>(m2)</span>
<span id="cb36-240"><a href="#cb36-240" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the R^2</span></span>
<span id="cb36-241"><a href="#cb36-241" aria-hidden="true" tabindex="-1"></a>m2_summary<span class="sc">$</span>r.squared</span>
<span id="cb36-242"><a href="#cb36-242" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-243"><a href="#cb36-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-244"><a href="#cb36-244" aria-hidden="true" tabindex="-1"></a>The $R^2$ has reduced from 95% to 38%, meaning that without the inclusion of input variable $x_2$ in our model, we reduce our ability to explain (i.e., predict) the outcome $y$ by approximately 60%. </span>
<span id="cb36-245"><a href="#cb36-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-246"><a href="#cb36-246" aria-hidden="true" tabindex="-1"></a><span class="fu">### Adjusted $R^2$</span></span>
<span id="cb36-247"><a href="#cb36-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-248"><a href="#cb36-248" aria-hidden="true" tabindex="-1"></a>Another measure in the <span class="in">`summary`</span> of <span class="in">`lm()`</span> output is an "adjusted" value of $R^2$, which penalizes the value of $R^2$ for models that have a lot of parameters ($p$) compared to the number of data points ($n$).</span>
<span id="cb36-249"><a href="#cb36-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-250"><a href="#cb36-250" aria-hidden="true" tabindex="-1"></a>$$\text{Adjusted } R^2 = 1 - \frac{n-1}{n-p} + \frac{n-1}{n-p} R^2$$</span>
<span id="cb36-251"><a href="#cb36-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-254"><a href="#cb36-254" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb36-255"><a href="#cb36-255" aria-hidden="true" tabindex="-1"></a>adjusted_r2 <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> (n<span class="dv">-1</span>)<span class="sc">/</span>(n<span class="sc">-</span>p) <span class="sc">+</span> (n<span class="dv">-1</span>)<span class="sc">/</span>(n<span class="sc">-</span>p)<span class="sc">*</span>r2</span>
<span id="cb36-256"><a href="#cb36-256" aria-hidden="true" tabindex="-1"></a>adjusted_r2</span>
<span id="cb36-257"><a href="#cb36-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-258"><a href="#cb36-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Compared to lm() output</span></span>
<span id="cb36-259"><a href="#cb36-259" aria-hidden="true" tabindex="-1"></a>m1_summary<span class="sc">$</span>adj.r.squared</span>
<span id="cb36-260"><a href="#cb36-260" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb36-261"><a href="#cb36-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-262"><a href="#cb36-262" aria-hidden="true" tabindex="-1"></a>If you have more parameters (i.e., more input variables) relative to the number of observed data points, then the Adjusted $R^2$ will be less than $R^2$. In the model above, we have many data points ($n=80$) relative to the number of input variables ($p-1 = 4$), so there is only a small difference in the two metrics. </span>
<span id="cb36-263"><a href="#cb36-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-264"><a href="#cb36-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-265"><a href="#cb36-265" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb36-266"><a href="#cb36-266" aria-hidden="true" tabindex="-1"></a><span class="fu">## Congratulations!</span></span>
<span id="cb36-267"><a href="#cb36-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-268"><a href="#cb36-268" aria-hidden="true" tabindex="-1"></a>Look at the <span class="in">`summary()`</span> of the <span class="in">`lm()`</span> output. You should now be able to explain (and manually calculate) every value that is printed in that output. You now have a deep understanding of the ordinary least squares (OLS) regression analysis and associated methods of hypothesis-testing.</span>
<span id="cb36-269"><a href="#cb36-269" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>